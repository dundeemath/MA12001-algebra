[
  {
    "objectID": "week9.html",
    "href": "week9.html",
    "title": "Week 9: Spheres",
    "section": "",
    "text": "\\[\n\\newenvironment{amatrix}[1]{%\n  \\left[\\begin{array}{#1}\n}{%\n  \\end{array}\\right]\n}\n\\]\nA final object which is particularly easy to describe in three dimensions is a sphere. Unlike lines and planes, these are not linear: you cannot add a vector to a point on a sphere to get another point on the sphere.\nInstead, we define a sphere in terms of its centre, with a position vector \\({\\mathbf{a}}\\) say, and a radius \\(R&gt;0\\). Then the sphere is the set of all points whose distance from the centre is equal to the radius, that is \\[\n|{\\mathbf{r}}-{\\mathbf{a}}| = R.\n\\] It’s normal to square this, because the magnitude \\(|\\cdot|\\) adds an ugly square root otherwise, giving \\[\n|{\\mathbf{r}}-{\\mathbf{a}}|^2 = R^2\n\\] or expanding this out \\[\n(x-a_1)^2 + (y-a_2)^2 + (z-a_3)^2 = R^2.\n\\]\nThink: what’s the equation for a sphere of radius 2 centred on the origin?\nThink: what is the centre and radius of the sphere given by \\[\n(x-2)^2 + y^2 + (z+1)^2 = 9?\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week9.html#example",
    "href": "week9.html#example",
    "title": "Week 9: Spheres",
    "section": "Example",
    "text": "Example\nFind the centre and radius of the sphere described by the equation \\[\nx^2  + y^2 + z^2 - 6x -4y   + 2z - 4 = 0.\n\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis isn’t currently in the general form we saw above, so we need to manipulate this equation until it looks like we want. In particular, we need to use completeing the square: \\[\n\\begin{aligned}\n0&=x^2  + y^2 + z^2 - 6x -4y   + 2z - 4 \\\\\n&= \\left(x-\\frac{6}{2}\\right)^2 - \\frac{6^2}{2^2} + \\left(y-\\frac{4}{2}\\right)^2 - \\frac{4^2}{2^2} + \\left(z+\\frac{2}{2}\\right)^2 - \\frac{2^2}{2^2} - 4\\\\\n&= (x-3)^2 + (y-2)^2 + (z+1)^2 - 9 - 4 - 1 - 4\n\\end{aligned}\n\\] so \\[\n(x-3)^2 + (y-2)^2 + (z+1)^2 = 16 = 4^2.\n\\] Finally this gives a centre of \\((3,2,-1)\\) and a radius of \\(4\\).",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week9.html#the-distance-between-a-sphere-and-a-point-line-or-plane.",
    "href": "week9.html#the-distance-between-a-sphere-and-a-point-line-or-plane.",
    "title": "Week 9: Spheres",
    "section": "The distance between a sphere and a point, line or plane.",
    "text": "The distance between a sphere and a point, line or plane.\nThis sounds hard but it’s actually very easy:\n\nFind the distance from the point/line/plane and the centre of the sphere (a point)\nSubstract the sphere’s radius from this distance\n\nThink: what’s the distance between the sphere of radius 5 centred at \\((4,1,8)\\) and the origin?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe distance between the centre of the sphere and the origin is \\(\\sqrt{4^2+1^2+8^2}=\\sqrt{81}=9\\), so the distance of the sphere from the origin is \\(9-5=4\\).",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week9.html#the-intersection-of-a-line-and-a-sphere",
    "href": "week9.html#the-intersection-of-a-line-and-a-sphere",
    "title": "Week 9: Spheres",
    "section": "The intersection of a line and a sphere",
    "text": "The intersection of a line and a sphere\nFollowing similar things in the previous weeks, to find intersections we just take the two equations and solve them together.\nThe crucial thing is to think (geometrically) about how many solutions to expect. A line can intersect a sphere at two points, or it can not intersect, or the line can just touch the sphere at one point.\nA general line is (going through \\({\\mathbf{a}}\\) with direction \\({\\mathbf{s}}\\)) \\[\n{\\mathbf{r}} = {\\mathbf{a}} + \\lambda{\\mathbf{s}}\n\\] and a general sphere is (radius \\(R\\), centre \\({\\mathbf{c}}\\)) \\[\n|{\\mathbf{r}}-{\\mathbf{c}}|^2 = R^2.\n\\]\nSubstituting the first into the second gives \\[\n|{\\mathbf{a}} + \\lambda{\\mathbf{s}}-{\\mathbf{c}}|^2 = R^2,\n\\] which is just a quadratic equation for \\(\\lambda\\) which we can solve. Quadratic equations have 0, 1 or 2 (real) solutions, so this makes sense.\n\n\n\n\n\n\nNote\n\n\n\nThe number of solutions of the quadratic tells us the number of intersection points.\n\n\nThen we can use the value(s) of \\(\\lambda\\) to find the points from the line equation.\n\nExample\nFind the intersection points of the line \\[\n{\\mathbf{r}} = [1,0,0] + \\lambda[0,1,0]\n\\] with the sphere \\[\nx^2+y^2+(z-1)^2 = 4.\n\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe components of the line equation are \\[\n\\begin{aligned}\nx&=1,\\\\\ny&=\\lambda,\\\\\nz&=0.\n\\end{aligned}\n\\] Substituting these into the sphere equation gives \\[\n1 + \\lambda^2 + (-1)^2 = 4\n\\] so \\(\\lambda^2 = 2\\).\nThis means our two parameter values are \\(\\lambda=\\pm\\sqrt{2}\\), and so the points are \\((1,\\sqrt{2},0)\\) and \\((1,-\\sqrt{2},0)\\).\n(Now check these points satisfy both our line and sphere equations.)",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week9.html#the-intersection-of-a-plane-and-a-sphere",
    "href": "week9.html#the-intersection-of-a-plane-and-a-sphere",
    "title": "Week 9: Spheres",
    "section": "The intersection of a plane and a sphere",
    "text": "The intersection of a plane and a sphere\nThis one’s a bit different. Now there are either no intersection points, exactly one point (if the plane just touches the sphere), or the plane and the sphere intersect on a circle.\n\nSuppose we have a sphere \\(|{\\mathbf{r}}-{\\mathbf{a}}|^2=R^2\\) and a plane \\({\\mathbf{r}}\\cdot{\\mathbf{n}} = d\\).\nWhat we want to find is the radius \\(\\alpha\\) of the circle, and its centre \\({\\mathbf{c}}\\): \nWe do this as follows: 1. Find the nearest point on the plane to the centre of the sphere \\({\\mathbf{a}}\\). This is \\({\\mathbf{c}}\\), the centre of the circle. 2. Find the distance between \\({\\mathbf{a}}\\) and \\({\\mathbf{c}}\\). 3. By Pythogoras’s theorem, since this is a right-angled triangle, \\(\\alpha^2+|{\\mathbf{c}}-{\\mathbf{a}}|^2 = R^2\\), so we can find \\(\\alpha\\).\nThe first two steps are exactly the same as finding the distance between a plane and a point – see last week’s notes.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week9.html#the-intersection-of-two-spheres",
    "href": "week9.html#the-intersection-of-two-spheres",
    "title": "Week 9: Spheres",
    "section": "The intersection of two spheres",
    "text": "The intersection of two spheres\nThis case is hard to visualise, but hopefully you can imagine that two spheres intersect on a circle, just as in the case of a sphere with a plane. In fact, the easiest way to do this is to first find the plane the circle lives on, and then do exactly the same method as before.\nSay we have spheres \\[\n|{\\mathbf{r}}-{\\mathbf{a}}_1|^2 = R_1^2\\] and \\[\n|{\\mathbf{r}}-{\\mathbf{a}}_2|^2 = R_2^2.\\]\nRemembering that \\(|{\\mathbf{r}}|^2 = {\\mathbf{r}}\\cdot{\\mathbf{r}}\\), we can expand these out as \\[\n{\\mathbf{r}}\\cdot{\\mathbf{r}}-2{\\mathbf{r}}\\cdot{\\mathbf{a}}_1 + {\\mathbf{a}}_1\\cdot{\\mathbf{a}}_1 = R_1^2\\] and \\[\n{\\mathbf{r}}\\cdot{\\mathbf{r}}-2{\\mathbf{r}}\\cdot{\\mathbf{a}}_2 + {\\mathbf{a}}_2\\cdot{\\mathbf{a}}_2 = R_2^2\\] and then subtract these equations to get rid of the \\({\\mathbf{r}}\\cdot{\\mathbf{r}}\\) terms: \\[\n-2{\\mathbf{r}}\\cdot{\\mathbf{a}}_1 + {\\mathbf{a}}_1\\cdot{\\mathbf{a}}_1+2{\\mathbf{r}}\\cdot{\\mathbf{a}}_2 - {\\mathbf{a}}_2\\cdot{\\mathbf{a}}_2 = R_1^2 - R_2^2.\\] This simplifies to \\[\n{\\mathbf{r}}\\cdot\\left(2{\\mathbf{a}}_2-2{\\mathbf{a}}_1 \\right) = R_1^2-R_2^2 + {\\mathbf{a}}_2\\cdot{\\mathbf{a}}_2 - {\\mathbf{a}}_1\\cdot{\\mathbf{a}}_1\n\\] which is exactly in the form \\({\\mathbf{r}}\\cdot{\\mathbf{n}} = d\\), so this is the equation of the plane!\nLet’s put all of this together in a final example:",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week9.html#example-2",
    "href": "week9.html#example-2",
    "title": "Week 9: Spheres",
    "section": "Example",
    "text": "Example\nFind the radius and centre of the circle of intersection of the spheres \\[\n(x-1)^2 + y^2 + (z+1)^2 = 4\n\\] and \\[\n(x+3)^2 + y^2 + z^2 = 5.\n\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst we expand out the equations: \\[\nx^2 + y^2 + z^2 -2x + 2z - 2 = 0\n\\] and \\[\nx^2+y^2+z^2 +6x + 4 = 0.\n\\] Subtracting these (cancelling out the quadratic terms): \\[\n-8x +2z - 6 = 0\n\\] which simplifies to \\[\n4x - z = -3.\n\\]\nSo the plane of intersection is \\(4x - z = -3\\), with normal \\([4,0,-1]\\).\nNext, we need to find the centre of the circle of intersection. This is the point \\((c_1,c_2,c_3)\\) which is in a direction \\([4,0,-1]\\) from the centre of the first sphere \\((1,0,-1)\\).\nSo \\[\n[c_1,c_2,c_3] = [1,0,-1] + \\lambda[4,0,-1]\n\\] for some \\(\\lambda\\).\nPlugging these into the plane equation \\(4x-z=-3\\) gives \\[\n4(1+4\\lambda) - (-1-\\lambda)=-3\n\\] so \\(\\lambda = -8/17\\), which means the centre of the circle is is \\({\\mathbf{c}} = [-15/17, 0, -9/17]\\).\nThe distance of the centre of the circle from the centre of the first sphere is \\[\n|{\\mathbf{c}}-[1,0,-1]| = \\sqrt{(-32/17)^2+0^2+(8/17)^2} = \\sqrt{1088}/17\\]\nThen finally using Pythagoras we know that the radius of the circle \\(\\alpha\\) satisfies \\[\n\\alpha^2 + (\\sqrt{1088}/17)^2 = 2^2\\] because the radius of the first sphere is 2, so \\(\\alpha = \\sqrt{4- 1088/289} = 2/\\sqrt{17}\\).",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 9: Spheres"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "Week 7: Lines",
    "section": "",
    "text": "\\[\n\\newenvironment{amatrix}[1]{%\n  \\left[\\begin{array}{#1}\n}{%\n  \\end{array}\\right]\n}\n\\]\nThis next section of the module uses vectors to think about geometry. We’ll describe lines, planes and spheres in terms of a general point with position vector \\({\\mathbf{r}}\\). Whenever you see \\({\\mathbf{r}}\\), you should think of a generic point that satisfies some conditions (like being on a plane), rather than \\({\\mathbf{a}}\\), \\({\\mathbf{b}}\\), \\({\\mathbf{c}}\\) which are usually particular points in space.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 7: Lines"
    ]
  },
  {
    "objectID": "week7.html#example",
    "href": "week7.html#example",
    "title": "Week 7: Lines",
    "section": "Example",
    "text": "Example\nFind an equation for the line going through the points \\(A\\) and \\(B\\) with position vectors \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNow we don’t know the direction of the line, but we can easily find it as the displacement vector \\({\\overrightarrow{AB}}={\\mathbf{b}}-{\\mathbf{a}}\\).\nWe already know two points on the line. Picking \\({\\mathbf{a}}\\) gives the final answer\n\\[\n{\\mathbf{r}} = {\\mathbf{a}}+ \\lambda \\left({\\mathbf{b}}-{\\mathbf{a}}\\right).\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 7: Lines"
    ]
  },
  {
    "objectID": "week7.html#example-1",
    "href": "week7.html#example-1",
    "title": "Week 7: Lines",
    "section": "Example",
    "text": "Example\nFind the distance of the point \\((1,1,0)\\) from the line \\[\n{\\mathbf{r}} = [0,0,1] + \\lambda [1,1,1].\n\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFollowing the above method, the nearest point on the line is when \\[\n\\left([1,1,0] - [0,0,1] - \\lambda [1,1,1]\\right)\\cdot [1,1,1] = 0,\n\\] which gives \\[\n1 - 3\\lambda  = 0,\n\\] so \\(\\lambda = 1/3\\).\nThe point is \\({\\mathbf{r}} = [0,0,1] +  [1,1,1]/3 = [1/3,1/3,4/3]\\), and so the distance between this and the original point is \\[\n\\left| [1,1,0] - [1/3,1/3,4/3]\\right| = \\sqrt{4/9 + 4/9 + 16/9} = 4\\sqrt{2}/3.\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 7: Lines"
    ]
  },
  {
    "objectID": "week7.html#example-2",
    "href": "week7.html#example-2",
    "title": "Week 7: Lines",
    "section": "Example",
    "text": "Example\nFind the point of intersection of the lines \\[\n\\mathbf{r} = [0,0,1] + \\lambda[1,1,0]\\] and \\[\n\\mathbf{r} = [2,0,1] + \\mu[1,0,0].\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEquating the two lines and rewriting as simulatenous equations gives \\[\n\\begin{aligned}\n\\lambda &= 2+\\mu,\\\\\n\\lambda &= 0,\\\\\n1 &= 1.\n\\end{aligned}\n\\] The final equation is automatically true, and the second equation just gives you the value of \\(\\lambda=0\\), so the first one tells us that \\(\\mu=-2\\).\nThen the intersection point is just \\([2,0,1] - 2[1,0,0]=[0,0,1]\\), which is indeed a point on both lines.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 7: Lines"
    ]
  },
  {
    "objectID": "week7.html#the-distance-between-two-lines",
    "href": "week7.html#the-distance-between-two-lines",
    "title": "Week 7: Lines",
    "section": "The distance between two lines",
    "text": "The distance between two lines\nWe saw that two lines in 3D don’t generally intersect. If they don’t, is there a well defined distance between them? If the lines are parallel, it’s kind of intuitively obvious that there’s a fixed distance between them.\nIf lines aren’t parallel (which we sometimes describe as the lines being skew) then in fact we can find a minimum distance between them. If the lines intersect, this is zero, but otherwise it’s some positive number.\nSuppose we have two lines with equations \\[\n{\\mathbf{r}} = {\\mathbf{a}} + \\lambda{\\mathbf{b}}\n\\] and \\[\n{\\mathbf{r}} = {\\mathbf{c}} + \\mu{\\mathbf{d}}.\n\\]\nThink about the displacement vector between a point \\(P\\) on the first line, with parameter value \\(\\lambda\\), and a point \\(Q\\) on the second line with parameter \\(\\mu\\): \\[\n{\\overrightarrow{PQ}} = ({\\mathbf{c}} + \\mu{\\mathbf{d}}) - ({\\mathbf{a}} + \\lambda{\\mathbf{b}}).\n\\]\nHopefully you can convince yourself that the distance between the lines – the magnitude of this displacement vector \\(|{\\overrightarrow{PQ}}|\\) – is shortest when this displacement is perpendicular to both lines.4\nSo then we must have \\[\n{\\mathbf{b}}\\cdot{\\overrightarrow{PQ}}=0\n\\] and \\[\n{\\mathbf{d}}\\cdot{\\overrightarrow{PQ}}=0.\n\\]\nExpanding these out gives \\[\n0={\\mathbf{b}}\\cdot({\\mathbf{c}} + \\mu{\\mathbf{d}} - {\\mathbf{a}} - \\lambda{\\mathbf{b}})\n\\] and \\[\n0={\\mathbf{d}}\\cdot({\\mathbf{c}} + \\mu{\\mathbf{d}} - {\\mathbf{a}} - \\lambda{\\mathbf{b}}).\n\\] These are two equations for two unknowns, so we can solve for \\(\\lambda\\) and \\(\\mu\\) and hence find the shortest distance \\(|{\\overrightarrow{PQ}}|\\).\n\nExample\nWhat is the shortest distance between the lines \\({\\mathbf{r}} = [1,1,5]+\\lambda[1,-1,2]\\) and \\({\\mathbf{r}}=[4,2,-7]+\\mu[1,1,4]\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe displacement is \\[\n{\\overrightarrow{PQ}} = [3,1,-12] +\\mu[1,1,4]+\\lambda[-1,1,-2].\n\\] If this vector is perpedicular to both \\([1,1,4]\\) and \\([1,-1,2]\\) then \\[\n0 = [1,1,4]\\cdot[3,1,-12] + \\mu [1,1,4]\\cdot[1,1,4]+\\lambda[1,1,4]\\cdot[-1,1,-2] = -44 + 18\\mu -8\\lambda\n\\] and \\[\n0 = [1,-1,2]\\cdot[3,1,-12] + \\mu [1,-1,2]\\cdot[1,1,4]+\\lambda[1,-1,2]\\cdot[-1,1,-2] = -22 + 8\\mu -6\\lambda\n\\] i.e. the linear system of equations \\[\n\\begin{aligned}\n18\\mu-8\\lambda &= 44,\\\\\n8\\mu-6\\lambda&=22,\n\\end{aligned}\n\\] which has the unique solution \\(\\lambda=-1\\), \\(\\mu=2\\).\nSo finally the distance between the lines is \\[\n|{\\overrightarrow{PQ}}| = \\left| [3,1,-12] +2[1,1,4]-1[-1,1,-2]\\right| = \\left|[6,2,-2]\\right| = \\sqrt{36+4+4} = \\sqrt{44}.\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 7: Lines"
    ]
  },
  {
    "objectID": "week7.html#footnotes",
    "href": "week7.html#footnotes",
    "title": "Week 7: Lines",
    "section": "Footnotes",
    "text": "Footnotes\n\n\notherwise we talk about “curves”, “half lines” and “line segments”↩︎\nBut don’t feel like you need to use Greek letters if you’d be more comfortable with \\(p\\) and \\(q\\) or whatever.↩︎\nFor 3D vectors.↩︎\nIf this doesn’t seem obvious to you, it turns into a calculus exercise to find the minimum of a function of two variables, which is a bit too messy to show here.↩︎",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 7: Lines"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "",
    "text": "\\[\n\\newenvironment{amatrix}[1]{%\n  \\left[\\begin{array}{#1}\n}{%\n  \\end{array}\\right]\n}\n\\]\nLast week, we saw that for a matrix \\[\nA = \\begin{bmatrix} a&b\\\\c&d \\end{bmatrix},\n\\] the inverse is \\[\nA^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix} d &-b\\\\ -c & a \\end{bmatrix}.\n\\]\nThis inverse exists if and only if \\(ad-bc\\neq 0\\). We call this quantity \\(ad-bc\\) the determinant, and write \\[\\det{A}=ad-bc.\\] You can think of the determinant as a bit like the discriminant for quadratic equations. It determines whether the matrix is invertible or singular.\nSometimes we also write the determinant as \\(|A|\\), but I’ll avoid this notation because it’s different from the absolute value of a scalar or magnitude of a vector. The determinant can be negative.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#example",
    "href": "week5.html#example",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "Example",
    "text": "Example\nIs the matrix \\[\nA=\\begin{bmatrix} 1&2&3\\\\3&6&9\\\\2&1&1 \\end{bmatrix}\n\\] invertible? Justify your answer.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we do the full determinant calculation we find that \\[\n\\det A = 0,\n\\] so it is singular, it is not invertible.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#swapping-two-rows-in-a-matrix",
    "href": "week5.html#swapping-two-rows-in-a-matrix",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "Swapping two rows in a matrix",
    "text": "Swapping two rows in a matrix\nIf we left-multiply a \\(3\\times3\\) matrix by the matrix \\(\\begin{bmatrix} 1 & 0 &0 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}\\), the result is that the second and third rows get swapped: \\[\n\\begin{bmatrix} 1 & 0 &0 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} 1 & 2 & 3\\\\4&5&6\\\\7&8&9 \\end{bmatrix} = \\begin{bmatrix} 1 & 2 & 3\\\\7&8&9\\\\4&5&6 \\end{bmatrix}.\n\\] Go through this multiplication slowly to convince yourself.\nThink: what matrix would swap the first and third rows and leave the second row as it is?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\begin{bmatrix} 0&0&1\\\\0 & 1 & 0\\\\1&0&0 \\end{bmatrix}.\n\\]",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#multiplying-a-row-by-a-scalar",
    "href": "week5.html#multiplying-a-row-by-a-scalar",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "Multiplying a row by a scalar",
    "text": "Multiplying a row by a scalar\nIf we left-multiply a \\(3\\times3\\) matrix by the matrix \\(\\begin{bmatrix} 1 & 0 &0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0.5 \\end{bmatrix}\\), the result is that the third row is multiplied by \\(0.5\\): \\[\n\\begin{bmatrix} 1 & 0 &0 \\\\ 0 &1 & 0 \\\\ 0 & 0 & 0.5 \\end{bmatrix}\\begin{bmatrix} 1 & 2 & 3\\\\4&5&6\\\\7&8&9 \\end{bmatrix} = \\begin{bmatrix} 1 & 2 & 3\\\\4&5&6\\\\3.5&4&4.5 \\end{bmatrix}.\n\\] Go through this multiplication slowly to convince yourself.\nThink: what matrix would multiply the first row by 3?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\begin{bmatrix} 3&0&0\\\\0&1&0\\\\0&0&1 \\end{bmatrix}.\n\\]",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#adding-a-multiple-of-one-row-to-another-row",
    "href": "week5.html#adding-a-multiple-of-one-row-to-another-row",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "Adding a multiple of one row to another row",
    "text": "Adding a multiple of one row to another row\nIf we left-multiply a \\(3\\times3\\) matrix by the matrix \\(\\begin{bmatrix} 1 & 0 &0 \\\\ 0 & 1 & 0 \\\\ 2 & 0 & 1 \\end{bmatrix}\\), the result is that we add \\(2\\times\\) the first row to the third row: \\[\n\\begin{bmatrix} 1 & 0 &0 \\\\ 0 &1 & 0 \\\\ 1 & 0 & 1 \\end{bmatrix}\\begin{bmatrix} 1 & 2 & 3\\\\4&5&6\\\\7&8&9 \\end{bmatrix} = \\begin{bmatrix} 1 & 2 & 3\\\\4&5&6\\\\9&12&15 \\end{bmatrix}.\n\\] Go through this multiplication slowly to convince yourself.\nThink: what matrix would add \\(4\\times\\) the first row to the second row?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\begin{bmatrix} 1&0&0\\\\4&1&0\\\\0&0&1 \\end{bmatrix}.\n\\]",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#the-bigger-picture",
    "href": "week5.html#the-bigger-picture",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "The bigger picture",
    "text": "The bigger picture\nWhy is this interesting? Firstly, notice that to get the matrix that performs these row oeprations, you just need to do the row operation to the identity matrix.\nSecondly suppose you have a series of row operation matrices, let’s call them \\(P_1\\), \\(P_2\\), etc., and you perform them one after another on a matrix \\(A\\):\n\\[\nP_5 P_4 P_3 P_2 P_1 A.\n\\] (Because we’re left multiplying, the order is reversed!)\nIf the result of this is the identity, then we have found the inverse of A! \\[\n(P_5 P_4 P_3 P_2 P_1) A = I\n\\] means that \\[\nA^{-1}=(P_5 P_4 P_3 P_2 P_1).\n\\] Remember that inverses are unique for square matrices, so if \\(BA=I\\) then \\(B=A^{-1}\\).",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#augmented-matrices",
    "href": "week5.html#augmented-matrices",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "Augmented matrices",
    "text": "Augmented matrices\nIn order to compute \\(3\\times3\\) matrix inverses, we need to introduce a new notation, called augmented matrices. This is just two matrices with the same number of rows, stuck side-by-side:\nIf \\(A=\\begin{bmatrix} 1&2&3\\\\4&5&6\\\\7&8&9 \\end{bmatrix}\\) and \\(B=\\begin{bmatrix} 0&9&8\\\\7&6&5\\\\4&3&2 \\end{bmatrix}\\) then the augmented matrix \\([A|B]\\) is \\[\n[A|B]=\\begin{amatrix}{ccc|ccc}\n1&2&3&0&9&8\\\\4&5&6&7&6&5\\\\7&8&9&4&3&2\n\\end{amatrix}.\n\\]\nWhat this notation does is allow us to manipulate two different matrices at the same time using the same row operations, and it simplifies the whole procedure.\nFor example, taking the above matrix and subtracting \\(2\\times\\) the first row from the second row, we have\n\\[\n\\begin{aligned}\n&\\begin{amatrix}{ccc|ccc}\n1&2&3&0&9&8\\\\4&5&6&7&6&5\\\\7&8&9&4&3&2\n\\end{amatrix}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1&2&3&0&9&8\\\\2&1&0&7&-12&-11\\\\7&8&9&4&3&2\n\\end{amatrix} \\qquad R_2 \\to R_2 - 2 R_1\n\\end{aligned}\n\\]\nPlease make a point of writing out explicitly what row operation you’re doing so whoever’s marking your work can follow it.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#how-it-works",
    "href": "week5.html#how-it-works",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "How it works",
    "text": "How it works\nHere are the steps for finding the inverse of a \\(3\\times3\\) matrix \\(A\\):\n\nWrite an augmented matrix with the identity, i.e. \\([A|I]\\)\nPerform a series of row operations to get zeros below the diagonal and ones on the diagonal on the left hand side.\nPerform more row operations to get zeros above the diagonal.\nNow the left side of the augmented matrix should be the identity, and the right side is your inverse, \\([I|A^{-1}]\\).\n\nRemember that not all matrices have inverses. If you get stuck, it’s probably because the matrix is singular, and the determinant of the matrix will be zero. (But you could also have made a mistake, like forgetting to swap rows.)\n\n\n\n\n\n\nNote\n\n\n\nCalculate the determinant of a matrix before trying to find the inverse. If the determinant is zero, no inverse exists. If the determinant is not zero, this method will give you the inverse.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week5.html#example-1",
    "href": "week5.html#example-1",
    "title": "Week 5: Determinants and inverses of \\(3\\times 3\\) matrices",
    "section": "Example",
    "text": "Example\nFollowing the steps above, let’s find the inverse of \\[\nA=\\begin{bmatrix} 5 &1 &0\\\\5&5&-3\\\\-10&3&\\frac{9}{4} \\end{bmatrix}.\n\\] (First find the determinant to check it’s invertible!)\n\\[\n\\begin{aligned}\n&\\begin{amatrix}{ccc|ccc}\n5 &1 &0&1&0&0\\\\5&5&-3&0&1&0\\\\-10&3&\\frac{9}{4}&0&0&1\n\\end{amatrix}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\5&5&-3&0&1&0\\\\-10&3&\\frac{9}{4}&0&0&1\n\\end{amatrix} \\qquad R_1 \\to \\frac{1}{5}R_1 \\qquad \\text{(to get a 1 on the diagonal entry)}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\0&4&-3&-1&1&0\\\\-10&3&\\frac{9}{4}&0&0&1\n\\end{amatrix} \\qquad R_2 \\to R_2-5R_1 \\qquad \\text{(to get 0 below the diagonal)}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\0&4&-3&-1&1&0\\\\0&5&\\frac{9}{4}&2&0&1\n\\end{amatrix} \\qquad R_3 \\to R_3+10R_1 \\qquad \\text{(to get 0 in the bottom left)}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\0&1&-\\frac{3}{4}&-\\frac{1}{4}&\\frac{1}{4}&0\\\\0&5&\\frac{9}{4}&2&0&1\n\\end{amatrix} \\qquad R_2 \\to \\frac{1}{4}R_2 \\qquad \\text{(to get 1 on the diagonal)}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\0&1&-\\frac{3}{4}&-\\frac{1}{4}&\\frac{1}{4}&0\\\\0&0&6&\\frac{13}{4}&-\\frac{5}{4}&1\n\\end{amatrix} \\qquad R_3 \\to R_3-5R_2 \\qquad \\text{(to get 0 below the diagonal)}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\0&1&-\\frac{3}{4}&-\\frac{1}{4}&\\frac{1}{4}&0\\\\0&0&1&\\frac{13}{24}&-\\frac{5}{24}&\\frac{1}{6}\n\\end{amatrix} \\qquad R_3 \\to \\frac{1}{6} R_3 \\qquad \\text{(to get 1 on the diagonal)}\n\\end{aligned}\n\\]\nWe’ve now completed the second step above. We’ve worked down from the top to get ones on the diagonal and zeros below. Now for the third step we work back upwards to get zeros above the diagonal:\n\\[\n\\begin{aligned}\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &\\frac{1}{5} &0&\\frac{1}{5}&0&0\\\\\n0&1&0&\\frac{5}{32}&\\frac{3}{32}&\\frac{1}{8}\\\\\n0&0&1&\\frac{13}{24}&-\\frac{5}{24}&\\frac{1}{6}\n\\end{amatrix} \\qquad R_2 \\to R_2 + \\frac{3}{4}R_3 \\qquad \\text{(to get 0 middle right)}\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|ccc}\n1 &0 &0&\\frac{27}{160}&-\\frac{3}{160}&-\\frac{1}{40}\\\\\n0&1&0&\\frac{5}{32}&\\frac{3}{32}&\\frac{1}{8}\\\\\n0&0&1&\\frac{13}{24}&-\\frac{5}{24}&\\frac{1}{6}\n\\end{amatrix} \\qquad R_1 \\to R_1 - \\frac{1}{5}R_2 \\qquad \\text{(to get 0 top middle)}\\\\\n\\end{aligned}\n\\]\nWe already have a zero in the top right, so we’re done! The left hand side is the identity, and the right hand side is the inverse.\n\\[\nA^{-1}=\\begin{bmatrix} \\frac{27}{160}&-\\frac{3}{160}&-\\frac{1}{40}\\\\\n\\frac{5}{32}&\\frac{3}{32}&\\frac{1}{8}\\\\\n\\frac{13}{24}&-\\frac{5}{24}&\\frac{1}{6} \\end{bmatrix}.\n\\]\nDoes it work? Calculate \\(A A^{-1}\\) and \\(A^{-1} A\\) to check.\nThere’s a general procedure here to get do divisions to get ones on the diagonal and subtraction/addition to get zeros. The problem comes when you have a zero where you need a one. In this case you have to swap rows. We’ll see examples of this in class and on the worksheets.\n\n\n\n\n\n\nNote\n\n\n\nThis process of finding the inverse is long and boring, but it’s straightforward if you take your time. Most of the marks are for understanding the method, because it’s very easy to make an arithmetic mistake.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 5: Determinants and inverses of $3\\times 3$ matrices"
    ]
  },
  {
    "objectID": "week3.html#the-dot-product",
    "href": "week3.html#the-dot-product",
    "title": "Week 3: Dot and cross products",
    "section": "The dot product",
    "text": "The dot product\nThe first type of multiplication is called the scalar product, because the result is a scalar. We will usually call it the dot product and you might also see inner product.\nThis operation is defined for \\(\\mathbb{R}^n\\) for all \\(n\\) as follows:\n\\[{\\mathbf{a}}\\cdot{\\mathbf{b}} = |{\\mathbf{a}}|\\,|{\\mathbf{b}}|\\,\\cos\\theta,\\]\nwhere \\(\\theta\\) is the angle between the two vectors.\n\n\nProperties\nFollowing the definition above and the set of rules for vectors, you can prove the following rules:\n\nIf \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) are perpendicular, \\({\\mathbf{a}}\\cdot{\\mathbf{b}}=0\\).\n\\({\\mathbf{a}}\\cdot{\\mathbf{b}} = 0\\) tells us that the vectors are perpendicular, or one of \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) is \\({\\mathbf{0}}\\);\n\\({\\mathbf{a}}\\cdot{\\mathbf{a}} = |{\\mathbf{a}}|^2\\);\n\\({\\mathbf{a}}\\cdot(\\lambda{\\mathbf{b}}) = \\lambda ({\\mathbf{a}}\\cdot{\\mathbf{b}})\\);\n\\({\\mathbf{a}}\\cdot{\\mathbf{b}} = {\\mathbf{b}}\\cdot{\\mathbf{a}}\\): the dot product is commutative;\n\\({\\mathbf{a}}\\cdot({\\mathbf{b}}+{\\mathbf{c}}) = {\\mathbf{a}}\\cdot{\\mathbf{b}} + {\\mathbf{a}}\\cdot{\\mathbf{c}}\\): the dot product is distributive over addition1.\n\n\n\nThe dot product with components\nA particularly important property becomes apparent when we find the dot product of vectors in components \\({\\mathbf{a}}=\\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3\\end{bmatrix}\\) and \\({\\mathbf{b}}=\\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3\\end{bmatrix}\\) using the rules above:\n\\[\n\\begin{aligned}\n{\\mathbf{a}}\\cdot{\\mathbf{b}} &= \\left(a_1 \\hat{{\\mathbf{x}}} + a_2 \\hat{{\\mathbf{y}}} + a_3\\hat{{\\mathbf{z}}}\\right)\\cdot\\left(b_1 \\hat{{\\mathbf{x}}} + b_2 \\hat{{\\mathbf{y}}} + b_3\\hat{{\\mathbf{z}}}\\right) \\\\\n&= a_1b_1 \\hat{{\\mathbf{x}}}\\cdot\\hat{{\\mathbf{x}}} + a_1b_2 \\hat{{\\mathbf{x}}}\\cdot\\hat{{\\mathbf{y}}} + a_1b_3 \\hat{{\\mathbf{x}}}\\cdot\\hat{{\\mathbf{z}}} +\na_2b_1 \\hat{{\\mathbf{y}}}\\cdot\\hat{{\\mathbf{x}}} + a_2b_2 \\hat{{\\mathbf{y}}}\\cdot\\hat{{\\mathbf{y}}} + a_2b_3 \\hat{{\\mathbf{y}}}\\cdot\\hat{{\\mathbf{z}}} \\\\ &\\;+\na_3b_1 \\hat{{\\mathbf{z}}}\\cdot\\hat{{\\mathbf{x}}} + a_3b_2 \\hat{{\\mathbf{z}}}\\cdot\\hat{{\\mathbf{y}}} + a_3b_3 \\hat{{\\mathbf{z}}}\\cdot\\hat{{\\mathbf{z}}} \\\\\n&= a_1b_1 + a_2b_2 + a_3b_3,\n\\end{aligned}\n\\]\nwhere we have used the facts that \\(\\hat{{\\mathbf{x}}}\\cdot\\hat{{\\mathbf{x}}}=\\hat{{\\mathbf{y}}}\\cdot\\hat{{\\mathbf{y}}}=\\hat{{\\mathbf{z}}}\\cdot\\hat{{\\mathbf{z}}}=1\\) and \\(\\hat{{\\mathbf{x}}}\\cdot\\hat{{\\mathbf{y}}}=\\hat{{\\mathbf{x}}}\\cdot\\hat{{\\mathbf{z}}}=\\hat{{\\mathbf{y}}}\\cdot\\hat{{\\mathbf{z}}}=0\\).\n\n\n\n\n\n\nNote\n\n\n\nTo calculate the dot product of two vectors, multiply the components together and add them up.\n\n\nThink: if \\({\\mathbf{a}}=\\begin{bmatrix} 2 \\\\ 1 \\\\ -1\\end{bmatrix}\\) and \\({\\mathbf{b}}=\\begin{bmatrix} 0 \\\\ 1 \\\\ 1\\end{bmatrix}\\), what is \\({\\mathbf{a}}\\cdot{\\mathbf{b}}\\)? What do you deduce about the vectors?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(2\\times0 + 1\\times1 + (-1)\\times1 = 0\\).\nThe dot product is zero and neither of the vectors is \\({\\mathbf{0}}\\) so the vectors are perpendicular.\n\n\n\n\n\n\n\n\n\nCommon mistake\n\n\n\nVery often people do something like \\(\\begin{bmatrix} 1 \\\\ 2 \\\\ 3\\end{bmatrix}\\cdot\\begin{bmatrix} 3 \\\\ 2 \\\\ 4\\end{bmatrix} = \\begin{bmatrix} 1\\times 3 \\\\ 2\\times 2 \\\\ 3\\times 4\\end{bmatrix}\\). This is WRONG because the result of the dot product must be a scalar, not a vector.\n\n\n\n\nExample for dot products\nShow that the diagonals of a rhombus are perpendicular.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet the corners of the rhombus be \\(A\\), \\(B\\), \\(C\\) and \\(D\\).\n\nIt’s a paralellogram, so \\({\\overrightarrow{AB}}={\\overrightarrow{DC}}\\) - let’s call this \\({\\mathbf{a}}\\) - and \\({\\overrightarrow{BC}}={\\overrightarrow{AD}}={\\mathbf{b}}\\).\nFuthermore, for a rhombus we know the side lengths are the same, so \\(|{\\mathbf{a}}| = |{\\mathbf{b}}|\\).\nWe want to show that \\({\\overrightarrow{AC}}\\cdot{\\overrightarrow{BD}} = 0\\).\nWe see from the diagram that \\({\\overrightarrow{AC}} = {\\mathbf{a}}+{\\mathbf{b}}\\) and \\({\\overrightarrow{BD}} = {\\mathbf{b}}-{\\mathbf{a}}\\). Then\n\\[\n{\\overrightarrow{AC}}\\cdot{\\overrightarrow{BD}} = ({\\mathbf{a}}+{\\mathbf{b}})\\cdot({\\mathbf{b}}-{\\mathbf{a}}) = {\\mathbf{a}}\\cdot{\\mathbf{b}} - {\\mathbf{a}}\\cdot{\\mathbf{a}} + {\\mathbf{b}}\\cdot{\\mathbf{b}} - {\\mathbf{b}}\\cdot{\\mathbf{a}} = |{\\mathbf{b}}|^2-|{\\mathbf{a}}|^2 = 0.\n\\]",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 3: Dot and cross products"
    ]
  },
  {
    "objectID": "week3.html#the-cross-product",
    "href": "week3.html#the-cross-product",
    "title": "Week 3: Dot and cross products",
    "section": "The cross product",
    "text": "The cross product\nUnlike the dot product, which is valid in any dimensions, the cross product is only defined in three dimensions.2 Also unlike the dot product, the cross product of two vectors is a vector. For this reason it’s called the vector product. It’s written with a cross \\(\\times\\).3\nThe geometric definition is as follows:\n\nIf either \\({\\mathbf{a}}\\) or \\({\\mathbf{b}}\\) is \\({\\mathbf{0}}\\), or they’re parallel, then \\({\\mathbf{a}}\\times{\\mathbf{b}}={\\mathbf{0}}\\).\nOtherwise, find a vector the is perpendicular to both \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) using the right-hand rule:\n\n\n\n\nFigure by Izaak Neutelings, from https://tikz.net.\n\n\n\nThe magnitude of the result \\(|{\\mathbf{a}}\\times{\\mathbf{b}}| = |{\\mathbf{a}}||{\\mathbf{b}}|\\sin\\theta\\).\n\nNote the similarity to the dot product, but with sine instead of cosine, and the fact it’s a vector.\n\nProperties\nThe following properties have similarities and differences with the corresponding ones for the dot product:\n\nIf \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) are parallel, \\({\\mathbf{a}}\\times{\\mathbf{b}}={\\mathbf{0}}\\).\n\\({\\mathbf{a}}\\times{\\mathbf{b}} = {\\mathbf{0}}\\) tells us that the vectors are parallel, or one of \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) is \\({\\mathbf{0}}\\);\n\\({\\mathbf{a}}\\times{\\mathbf{a}} = {\\mathbf{0}}\\);\n\\({\\mathbf{a}}\\times(\\lambda{\\mathbf{b}}) = \\lambda ({\\mathbf{a}}\\times{\\mathbf{b}})\\);\n\\({\\mathbf{a}}\\times{\\mathbf{b}} = -{\\mathbf{b}}\\times{\\mathbf{a}}\\): the dot product is anticommutative;\n\\({\\mathbf{a}}\\times({\\mathbf{b}}+{\\mathbf{c}}) = {\\mathbf{a}}\\times{\\mathbf{b}} + {\\mathbf{a}}\\times{\\mathbf{c}}\\): the cross product is distributive over addition.\n\n\n\nThe cross product with components\nIf you apply the rules above, using the fact that \\(\\hat{{\\mathbf{x}}}\\times\\hat{{\\mathbf{y}}}=\\hat{{\\mathbf{z}}}\\) - which is called a right-handed coordinate system - you can prove the following important formula:\n\\[\n\\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3\\end{bmatrix} \\times \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3\\end{bmatrix} = \\begin{bmatrix} a_2b_3-a_3b_2 \\\\ a_3b_1-a_1b_3 \\\\ a_1b_2 - a_2b_1\\end{bmatrix}.\n\\]\nThis ugly formula is one of the only things in this module I recommend you learn by heart. There are patterns which can help you memorise it; try to find something that works for you.\n\n\n\n\n\n\nCommon mistake\n\n\n\nPeople mess up the second component of the cross product. It might be the negative of what you intuitively think it should be.\n\n\n\n\n\n\n\n\nNote\n\n\n\nMany people like to write the cross product as the determinant of a matrix, as in\n\\[\n\\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3\\end{bmatrix} \\times \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3\\end{bmatrix} = \\left|\\begin{matrix} \\hat{{\\mathbf{x}}} & \\hat{{\\mathbf{y}}} & \\hat{{\\mathbf{z}}} \\\\\na_1 & a_2 & a_3 \\\\\nb_1 & b_2 & b_3\n\\end{matrix}\\right|.\n\\]\nDon’t worry if you’re not familiar with determinants (or matrices), we’ll see them in a couple of weeks.\nI think this formula is stupid anyway because you can’t put vectors inside a matrix like that. But if it works for you, feel free to use it.\n\n\nThink: if \\({\\mathbf{a}}=\\begin{bmatrix} 2 \\\\ 1 \\\\ -1\\end{bmatrix}\\) and \\({\\mathbf{b}}=\\begin{bmatrix} 0 \\\\ 1 \\\\ 1\\end{bmatrix}\\), what is \\({\\mathbf{a}}\\times{\\mathbf{b}}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\begin{bmatrix} 1\\times 1-(-1)\\times 1 \\\\ -1\\times 0-2\\times 1 \\\\ 2\\times 1 - 1\\times 0\\end{bmatrix} = \\begin{bmatrix} 2 \\\\ -2 \\\\ 2\\end{bmatrix}.\\]\n\n\n\n\n\nApplications\nYou may remember the formula for the area of a triangle as \\(\\frac{1}{2} b c \\sin \\alpha\\) where \\(\\alpha\\) is the angle between the sides of length \\(b\\) and \\(c\\). Looking at the definition of the cross product, we see that\n\\[\\frac{1}{2}|{\\mathbf{a}}\\times{\\mathbf{b}}|\\]\nis the area of the triangle between \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\). Similarly, \\(|{\\mathbf{a}}\\times{\\mathbf{b}}|\\) is the area of the parallelogram with sides \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\):\n\n\n\nExample for cross products\nFind a unit vector that is perpendicular to both \\({\\mathbf{a}}=\\begin{bmatrix} 3 \\\\ 1 \\\\ 2\\end{bmatrix}\\) and \\({\\mathbf{b}}=\\begin{bmatrix} 1 \\\\ 1 \\\\ -1\\end{bmatrix}\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe know that the result of the cross product \\({\\mathbf{a}}\\times{\\mathbf{b}}\\) is perpendicular to both of them:\n\\[\\begin{bmatrix} 3 \\\\ 1 \\\\ 2\\end{bmatrix}\\times\\begin{bmatrix} 1 \\\\ 1 \\\\ -1\\end{bmatrix} = \\begin{bmatrix} -3 \\\\ 5 \\\\ 2\\end{bmatrix}.\\]\nThe question asks for a unit vector, so we need to divide this vector by its own magnitude. The magnitude is\n\\[\\sqrt{(-3)^2+5^2+2^2} = \\sqrt{38}\\]\nand so the final answer is\n\\[\\begin{bmatrix} \\frac{-3}{\\sqrt{38}} \\\\ \\frac{5}{\\sqrt{38}} \\\\ \\frac{2}{\\sqrt{38}}\\end{bmatrix}.\\]\nThe vector opposite to this, i.e. \\(\\begin{bmatrix} \\frac{3}{\\sqrt{38}} \\\\ \\frac{-5}{\\sqrt{38}} \\\\ \\frac{-2}{\\sqrt{38}}\\end{bmatrix}\\), would also satisfy the requirements.",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 3: Dot and cross products"
    ]
  },
  {
    "objectID": "week3.html#footnotes",
    "href": "week3.html#footnotes",
    "title": "Week 3: Dot and cross products",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is easiest to prove using the component form of the dot product, but unfortunately that gives a circular proof. To prove it directly requires a lot of geometry and trigonometry.↩︎\nSometimes people define a cross product in two dimensions by imagining the 2d vectors on a plane in 3d space, but we won’t use that definition.↩︎\nOccasionally you see people use \\(\\wedge\\) instead. In modern maths this the exterior product, which is a related but different concept.↩︎",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 3: Dot and cross products"
    ]
  },
  {
    "objectID": "week10.html",
    "href": "week10.html",
    "title": "Week 10: Complex numbers",
    "section": "",
    "text": "\\[\n\\newenvironment{amatrix}[1]{%\n  \\left[\\begin{array}{#1}\n}{%\n  \\end{array}\\right]\n}\n\\]\nThis last bit of the module is a bit disconnected from the rest, and builds on complex numbers that you’ve seen before.",
    "crumbs": [
      "Chapter 4: Complex numbers",
      "Week 10: Complex numbers"
    ]
  },
  {
    "objectID": "week10.html#complex-conjugates",
    "href": "week10.html#complex-conjugates",
    "title": "Week 10: Complex numbers",
    "section": "Complex conjugates",
    "text": "Complex conjugates\nWe define the conjugate of a complex number \\(z=a+ib\\) to be \\(\\overline{z}=a-ib\\). This is the complex number with the same real part but opposite imaginary part, or equivalently with the same modulus but opposite argument.\nNote that \\[\nz\\overline{z} = (a+ib)(a-ib) = a^2 + iba + a(-ib) + (ib)(-ib) = a^2 + b^2 = |z|^2.\n\\] This is a bit like how \\({\\mathbf{a}}\\cdot{\\mathbf{a}} = |{\\mathbf{a}}|^2\\) for vectors. But \\(z^2 \\neq |z|^2\\), unless \\(z\\) is real.\n\n\n\n\n\n\nNote\n\n\n\n\\[\nz\\overline{z} = |z|^2.\n\\]\n\n\n\nDivision of complex numbers\nUsing the complex conjugate we can easily divide complex numbers using just the rules for multiplication: \\[\n\\frac{z_1}{z_2} = \\frac{z_1\\times\\overline{z_2}}{z_2\\times\\overline{z_2}} = \\frac{z_1\\times\\overline{z_2}}{|z_2|^2}.\n\\]\nThink: what is \\(3+2i\\) divided by \\(2-i\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\n\\frac{3+2i}{2-i} = \\frac{(3+2i)(2+i)}{(2-i)(2+i)} = \\frac{6+3i+4i-2}{4+2i-2i+1} = \\frac{4+7i}{5} = \\frac{4}{5} + \\frac{7}{5} i.\n\\]",
    "crumbs": [
      "Chapter 4: Complex numbers",
      "Week 10: Complex numbers"
    ]
  },
  {
    "objectID": "week10.html#trigonometic-form",
    "href": "week10.html#trigonometic-form",
    "title": "Week 10: Complex numbers",
    "section": "Trigonometic form",
    "text": "Trigonometic form\nLooking at Figure 1 and use some simple triognometry, we see that \\(a=r\\cos\\theta\\) and \\(b=r\\sin\\theta\\). This gives the full trigonometric form for a complex number: \\[\nz = r\\left(\\cos\\theta+i\\sin\\theta\\right).\n\\]\n\nExample\nWrite the complex number \\(z=-2-2i\\) in polar form.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, draw an Argand diagram. We see that we must have \\(-\\pi &lt; \\arg z &lt; -\\pi/2\\), because it’s in the lower left quadrant. \\(\\tan^{-1} \\frac{-2}{-2} = \\tan^{-1} 1 = \\pi/4\\), but this doesn’t fit the right range, so we have to subtract \\(\\pi\\) to get \\(\\arg z = -3\\pi/4\\).\nEven better: just spot that \\(\\arg z = -3\\pi/4\\) from the diagram.\nSecond, \\(|z| = \\sqrt{(-2)^2+(-2)^2} = \\sqrt{8} = 2\\sqrt{2}\\).\nPutting this together, we get the answer: \\[\nz = 2\\sqrt{2}\\left(\\cos(-3\\pi/4) + \\sin(-3\\pi/4)\\right).\n\\]\n\n\n\nUsually, once you’ve written it in polar form, it’s easy to work out the cosine and sine and check it matches the original number.",
    "crumbs": [
      "Chapter 4: Complex numbers",
      "Week 10: Complex numbers"
    ]
  },
  {
    "objectID": "week10.html#exponential-form",
    "href": "week10.html#exponential-form",
    "title": "Week 10: Complex numbers",
    "section": "Exponential form",
    "text": "Exponential form\nFact: \\[e^{i\\theta} = \\cos\\theta + i\\sin\\theta.\n\\]\nBut then we can substitute this straight into the trigonometric formula for complex numbers to give \\[\nz = re^{i\\theta}.\n\\] Again, \\(r=|z|\\) is the modulus and \\(\\theta=\\arg z\\) is the argument.\n\nDemonstration of the fact\nThe proper mathematical definitions of the exponential function, sine and cosine are through the power series: \\[\n\\exp x = 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\dots\n\\] \\[\n\\cos \\theta = 1 - \\frac{\\theta^2}{2!} + \\frac{\\theta^4}{4!} + \\dots\n\\] \\[\n\\sin \\theta = \\frac{\\theta}{1!} - \\frac{\\theta^3}{3!} + \\frac{\\theta^5}{5!} + \\dots\n\\] Put \\(x=i\\theta\\) into the first one and you’ll see the result.",
    "crumbs": [
      "Chapter 4: Complex numbers",
      "Week 10: Complex numbers"
    ]
  },
  {
    "objectID": "week10.html#de-moivres-theorem",
    "href": "week10.html#de-moivres-theorem",
    "title": "Week 10: Complex numbers",
    "section": "De Moivre’s theorem",
    "text": "De Moivre’s theorem\nUsing exponential form, we can take powers of a complex number. \\[\nz^n = \\left(re^{i\\theta}\\right)^n = r^n e^{in\\theta}.\n\\] So in trig form, \\[\nz^n = r^n\\left(\\cos n\\theta+i\\sin n\\theta\\right).\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThis is the main thing to take away from this week.\n\n\nThis is one way to find formulas for \\(\\sin n\\theta\\) etc. We don’t even need \\(n\\) to be an integer.\n\nExample\nIf \\(z=1+i\\), what is \\(z^5\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOf course you could just multiply it by itself 4 times, but that would be very tedious and error-prone.\nInstead, we can transform it to polar form and then use de Moivre’s theorem to find the answer.\n\\(|z| = \\sqrt{1^2+1^2} = \\sqrt{2}\\).\nFrom a sketch or from the formula, \\(\\arg z = \\pi/4\\).\nSo that means \\(z = \\sqrt{2}\\left(\\cos\\pi/4 + i \\sin\\pi/4\\right)\\), and then de Movire tells us \\[\nz^5 =  \\sqrt{2}^5 \\left(\\cos5\\pi/4 + i \\sin5\\pi/4\\right) = 4\\sqrt{2} \\left(-1/\\sqrt{2} - i/\\sqrt{2}\\right) = -4 -4i.\n\\]\nTo get the values of \\(\\cos 5\\pi/4\\) you might find a little sketch of \\(\\cos x\\) helpful, and similarly for \\(\\sin\\).",
    "crumbs": [
      "Chapter 4: Complex numbers",
      "Week 10: Complex numbers"
    ]
  },
  {
    "objectID": "week10.html#example-2",
    "href": "week10.html#example-2",
    "title": "Week 10: Complex numbers",
    "section": "Example",
    "text": "Example\nFind all the solutions to the complex equation \\(z^4 = 16i\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst we find the modulus and argument of the right-hand side.\nIn this case it’s purely imaginary, so it’s easy (think graphically):\n\\(\\arg (16i) = \\pi/2\\), and \\(|16i| = 16\\).\nWe look for solutions in modulus-argument form. If \\(z=r\\left(\\cos \\theta + i\\sin\\theta\\right)\\) then we know\n\\[\nz^4=r^4 \\left(\\cos 4\\theta + i\\sin4\\theta\\right)\n\\] but also \\[\nz^4=16 \\left(\\cos \\pi/2 + i\\sin\\pi/2\\right)\n\\]\nSince \\(r\\geq0\\) is a real number, we can only have \\(r=2\\) to give \\(r^4=16\\).\nThe key point is to find different \\(\\theta\\) for the different solutions, so that \\[\n\\cos 4\\theta=\\cos \\pi/2 = 0\\] and \\[\n\\sin4\\theta =\\sin\\pi/2 = 1\\].\nThe trick is remembering that we can always add \\(2\\pi\\) and not change the values of sine and cosine:\n\\(4\\theta = \\pi/2\\) gives \\(\\theta=\\pi/8\\).\n\\(4\\theta+2\\pi = \\pi/2\\) gives \\(\\theta=-3\\pi/8\\).\n\\(4\\theta+4\\pi = \\pi/2\\) gives \\(\\theta=-7\\pi/8\\).\n\\(4\\theta+6\\pi = \\pi/2\\) gives \\(\\theta=-11\\pi/8\\).\n\\(4\\theta+8\\pi = \\pi/2\\) gives \\(\\theta=-15\\pi/8\\) BUT this is the same angle as \\(\\theta=\\pi/8\\), so we’ve already found all the solutions.\nNow we can write down all the possible answers:\n\\(z = 2 \\left(\\cos\\pi/8 + i\\sin\\pi/8\\right)\\)\n\\(z = 2 \\left(\\cos-3\\pi/8 + i\\sin-3\\pi/8\\right)\\)\n\\(z = 2 \\left(\\cos-7\\pi/8 + i\\sin-7\\pi/8\\right)\\)\n\\(z = 2 \\left(\\cos-11\\pi/8 + i\\sin-11\\pi/8\\right)\\)\nIf these were simpler expressions, or if you have a calculator, you could now expand these out to the usual form \\(z=a+ib\\).",
    "crumbs": [
      "Chapter 4: Complex numbers",
      "Week 10: Complex numbers"
    ]
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Helpful links",
    "section": "",
    "text": "https://www.3blue1brown.com/topics/linear-algebra\nThese are great videos explaining a lot of the material in this module, along with some stuff you definitely don’t need.\nhttps://phet.colorado.edu/en/simulations/vector-addition\nSome interactive demos to play with vectors.\nhttps://www.youtube.com/playlist?list=PL49CF3715CB9EF31D\nClassic lectures from MIT which go deeper but are very relevant to the matrix part of this module.\nhttps://www.cs.ox.ac.uk/files/12921/book.pdf\nA free textbook covering a lot of the module.\nhttps://www.3blue1brown.com/lessons/ldm-complex-numbers and https://www.3blue1brown.com/lessons/ldm-eulers-formula\nLong-form videos relevant to the final part of the module.",
    "crumbs": [
      "Helpful links"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA12001 Algebra",
    "section": "",
    "text": "This webpage contains the lecture notes for the algebra half of the Mathematics 1B (MA12001) module for University of Dundee.\n\nIntroduction\nThe module MA12001 is split into two halves. This half, which we call “algebra” basically because it isn’t “calculus”, covers several areas. First we’ll see the idea of vectors, which will be familiar to many of you. Then we’ll talk about matrices, which are a way to discuss transformations of vectors. This is a first introduction to a large and important area of mathematics called linear algebra. In the final section of the module we’ll use what we’ve learnt to describe different geometric objects like lines, planes and spheres.\nThese notes contain all the examinable material within this half of the module, and maybe also some bonus stuff, which will be clearly marked as non-examinable. For details of the organisation of the module this year, please see My Dundee.\nI’ll be updating these notes weekly as we go through, and at the end of the semester I’ll make the full set of these notes available as a PDF. If you’d like to read ahead, last year’s full notes are available on MyDundee.\nIt’s very likely that there are mistakes in these notes. If you find one, please let me know ASAP at mailto:jparker002@dundee.ac.uk, no matter how trivial you think the mistake is.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "Week 1: Displacement Vectors",
    "section": "",
    "text": "The word “vector” can be used to mean slightly different but closely related concepts. Here we use a definition based on physics, and later we will see how this relates to the more general and precise mathematical definition, and also the concept of vectors in computer science.\nScalars are mathematical objects that can be described by a single number. Common examples from physics include temperature, pressure and density. Vectors are defined by two things: a direction and a magnitude. Common examples are displacement, force, acceleration and velocity 1.\nA vector space is associated with a dimension. They can have any integer number of dimensions or even be infinite-dimensional, but in this module we will consider only two- and three-dimensional vectors, which are the ones that we can easily imagine and draw.\nIn this section of the course we will examine the mathematics of vectors.",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#equality",
    "href": "week1.html#equality",
    "title": "Week 1: Displacement Vectors",
    "section": "Equality",
    "text": "Equality\nTwo displacements are equal if their lengths and directions are equal.\nIn the diagram Figure 1 below, \\({\\overrightarrow{AD}} = {\\overrightarrow{BC}}\\) because the directions and lengths are the same, even though the endpoints are different. On the other hand, \\({\\overrightarrow{AD}} \\ne {\\overrightarrow{DA}}\\) because even though the lengths are the same, \\(|{\\overrightarrow{AD}}| = |{\\overrightarrow{DA}}|\\), the directions are not.\nThink: is \\({\\overrightarrow{AB}}\\) equal to \\({\\overrightarrow{CD}}\\) or \\({\\overrightarrow{DC}}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\({\\overrightarrow{CD}}\\) has the opposite direction. \\({\\overrightarrow{AB}} = {\\overrightarrow{DC}}\\).\n\n\n\n\n\n\n\n\n\nFigure 1: A parallelogram \\(ABCD\\)",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#adding-displacements",
    "href": "week1.html#adding-displacements",
    "title": "Week 1: Displacement Vectors",
    "section": "Adding displacements",
    "text": "Adding displacements\nAdding displacements is easy when the endpoint of the first displacement is the startpoint of the second. Consider this diagram:\n\n\n\n\n\n\nFigure 2: A triangle \\(ADF\\)\n\n\n\nHere we see that going from \\(D\\) to \\(A\\) and then from \\(A\\) to \\(F\\) is the same as going directly from \\(D\\) to \\(F\\). So we write \\({\\overrightarrow{DA}} + {\\overrightarrow{AF}} = {\\overrightarrow{DF}}\\).\nWithout knowing anything about the points \\(X\\), \\(Y\\) and \\(Z\\), we can say that \\({\\overrightarrow{XY}}+{\\overrightarrow{YZ}}={\\overrightarrow{XZ}}\\). We just “cancel” the middle letter.\n\n\n\n\n\n\nNote\n\n\n\nTo add two displacements with a common letter in the midddle, just cancel out that letter.\n\n\nIf there is no common middle letter, then we just need to remember that the displacements do not have a fixed position – we can “move” them. Sometimes it helps if we know other equivalent displacements. For example, in Figure 1, \\({\\overrightarrow{AD}} + {\\overrightarrow{AB}} = {\\overrightarrow{AD}} + {\\overrightarrow{DC}} = {\\overrightarrow{AC}}\\).\nThink: In Figure 1, what one displacement is equal to \\({\\overrightarrow{BC}} + {\\overrightarrow{DB}}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\({\\overrightarrow{BC}} = {\\overrightarrow{AD}}\\) so \\({\\overrightarrow{BC}} +{\\overrightarrow{DB}}= {\\overrightarrow{AD}} + {\\overrightarrow{DB}} = {\\overrightarrow{AB}}\\)\n\n\n\n\nTriangle inequality\nWhen we add displacements, the length of the result is NOT the two lengths added together, in general. It is not true that \\(|{\\overrightarrow{DA}}|+|{\\overrightarrow{AF}}|=|{\\overrightarrow{DF}}|\\). In fact, thinking about Figure 2 we can see that \\(|{\\overrightarrow{DA}}|+|{\\overrightarrow{AF}}|\\geq|{\\overrightarrow{DF}}|\\). This is called the triangle inequality.\n\n\nAddition is commutative\nIn mathematics we use special words to describe different operations. An operation is commutative if we can swap around the sides and get the same answer. For example, \\(2+5 = 5+2\\), so normal addition of scalars is commutative. That’s true of vector addition too!\nThink: of the other basic operations of scalars, \\(-\\), \\(\\times\\) and \\(\\div\\), which is commutative and which are not?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMultiplication is commutative, but subtraction and division are not: \\(3-2=1\\) but \\(2-3=-1\\) and \\(10\\div2 = 5\\) but \\(2\\div10 = 0.2\\).\n\n\n\nIn Figure 1, \\({\\overrightarrow{AD}} + {\\overrightarrow{DC}} = {\\overrightarrow{AC}}\\), and using the fact that \\({\\overrightarrow{DC}} = {\\overrightarrow{AB}}\\) and \\({\\overrightarrow{AD}} = {\\overrightarrow{BC}}\\), we see that \\({\\overrightarrow{DC}} + {\\overrightarrow{AD}} = {\\overrightarrow{AB}} + {\\overrightarrow{BC}} = {\\overrightarrow{AC}}\\), so we have proven that \\({\\overrightarrow{AD}} + {\\overrightarrow{DC}} = {\\overrightarrow{DC}} + {\\overrightarrow{AD}}\\).\n\n\nAddition is associative\nAn operation is associative if it doesn’t matter where we write brackets. For example, \\((3+2) + 5 = 3 + (2+5)\\). For associative operations, we don’t need to write the brackets at all, and it’s unambiguous to say “three plus five plus two”. (This isn’t true of subtraction. If someone said “ten minus two minus one” would the answer be 7 or 9? \\((10-2)-1\\) is not the same as \\(10-(2-1)\\).)\nLooking at Figure 1, we see that \\(({\\overrightarrow{AB}} + {\\overrightarrow{BC}}) + {\\overrightarrow{CD}} = {\\overrightarrow{AC}} + {\\overrightarrow{CD}} = {\\overrightarrow{AD}}\\), and \\({\\overrightarrow{AB}} + ({\\overrightarrow{BC}} + {\\overrightarrow{CD}}) = {\\overrightarrow{AB}} + {\\overrightarrow{BD}} = {\\overrightarrow{AD}}\\). Therefore, we have proven that \\(({\\overrightarrow{AB}} + {\\overrightarrow{BC}}) + {\\overrightarrow{CD}} = {\\overrightarrow{AB}} + ({\\overrightarrow{BC}} + {\\overrightarrow{CD}})\\). Addition of displacements is associative.\n\n\nThe zero displacement\nWith normal scalar numbers, we have the special number \\(0\\) which we can add to anything and not change the answer. \\(3+0=3\\), \\(0+10=10\\), etc.\nWe define a special displacement, denoted \\({\\mathbf{0}}\\), which we can add to any displacement and not change the answer. \\({\\overrightarrow{AB}} + {\\mathbf{0}} = {\\overrightarrow{AB}}\\), and also, by commutativity, \\({\\mathbf{0}} + {\\overrightarrow{AB}} = {\\overrightarrow{AB}}\\). We think of this displacement as starting at any point, and then not moving!\n\n\nNegative displacements\nEvery normal positive number has a corresponding negative number, and these have the special property that they add together to give \\(0\\). That is to say, \\(3+(-3) = 0\\).\nWe would like to have the same thing with displacements. What displacement can I add to \\({\\overrightarrow{AB}}\\) to get the zero displacement, i.e. to get back to where I started? Obviously, we should choose \\({\\overrightarrow{BA}}\\). So, \\({\\overrightarrow{AB}} + {\\overrightarrow{BA}} = {\\mathbf{0}}\\), and we write that \\(-{\\overrightarrow{BA}} = {\\overrightarrow{AB}}\\).\n\n\n\n\n\n\nNote\n\n\n\nTo take the negative of a displacement, just swap the letters round.\n\n\n\n\nSubtracting displacements\nWe define subtraction using the negatives in the obvious way, so \\({\\overrightarrow{AB}} - {\\overrightarrow{CB}} = {\\overrightarrow{AB}} + (-{\\overrightarrow{CB}}) = {\\overrightarrow{AB}} + {\\overrightarrow{BC}}\\).",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#multiplying-displacements",
    "href": "week1.html#multiplying-displacements",
    "title": "Week 1: Displacement Vectors",
    "section": "Multiplying displacements",
    "text": "Multiplying displacements\nFor now, let’s ignore the idea of multiplying two displacements together, and instead concentrate on multiplying displacements by scalars.\nWe can define multiplication by an integer in an obvious way: \\[\n3{\\overrightarrow{AB}} = {\\overrightarrow{AB}} + {\\overrightarrow{AB}} + {\\overrightarrow{AB}}.\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nFor normal numbers \\(ab\\), \\(a\\times b\\) and \\(a\\cdot b\\) are all the same thing. For vectors, we save the dot and cross for special meanings, and only ever use the first notation for multiplication of a scalar and a vector.\n\n\nHere the result of \\(3{\\overrightarrow{AB}}\\) is clearly in the same direction as \\({\\overrightarrow{AB}}\\), and it has three times the length. So in general, multiplying by a scalar results in a displacement in the same direction, but with the length changed.\n\n\n\n\n\n\nNote\n\n\n\nTo multiply a displacement by a negative number, first multiply by the positive number and then flip the direction.\n\n\n\nScalar multiplication is distributive over vector addition\nNow for some more jargon: an operation are distributive over another operation if we can expand out the brackets. So for normal multiplication and addition, \\(3\\times(5+2) = 3\\times 5+3\\times 2\\).\nWhat about for displacments? \\[\n2{\\overrightarrow{AB}} + 2{\\overrightarrow{XY}} = {\\overrightarrow{AB}} + {\\overrightarrow{AB}} + {\\overrightarrow{XY}} + {\\overrightarrow{XY}} = ({\\overrightarrow{AB}} + {\\overrightarrow{XY}}) + ({\\overrightarrow{AB}} + {\\overrightarrow{XY}}) = 2({\\overrightarrow{AB}}+{\\overrightarrow{XY}}).\n\\]\nThink: which of the other rules have we used in this derivation?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo write \\({\\overrightarrow{AB}} + {\\overrightarrow{AB}} + {\\overrightarrow{XY}} + {\\overrightarrow{XY}} = {\\overrightarrow{AB}} + {\\overrightarrow{XY}} + {\\overrightarrow{AB}} + {\\overrightarrow{XY}}\\), we have used commutativity of addition. To add the brackets in, we used associativity.\n\n\n\n\n\n\n\n\n\nFigure 3: The vector \\({\\overrightarrow{AC}}\\) is twice the length of \\({\\overrightarrow{AB}}\\) and in the same direction, so \\({\\overrightarrow{AC}}=2{\\overrightarrow{AB}}\\).\n\n\n\nIn Figure 3, we see that \\({\\overrightarrow{BC}}={\\overrightarrow{AB}}\\), so \\({\\overrightarrow{AC}}={\\overrightarrow{AB}}+{\\overrightarrow{BC}}=2{\\overrightarrow{AB}}\\).",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#dividing-by-a-scalar",
    "href": "week1.html#dividing-by-a-scalar",
    "title": "Week 1: Displacement Vectors",
    "section": "Dividing by a scalar",
    "text": "Dividing by a scalar\nWe’ve defined addition, subtraction and multiplication. What about division? To divide a vector by \\(2\\), just multiply by \\(\\frac{1}{2}\\).",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#colinear-points",
    "href": "week1.html#colinear-points",
    "title": "Week 1: Displacement Vectors",
    "section": "Colinear points",
    "text": "Colinear points\nThree (or more) points are colinear (they lie on the same line) if all the vectors between them are in the same or opposite directions, i.e. they can all be written as scalar multiples of each other.\nIn Figure 3, points \\(A\\), \\(B\\) and \\(C\\) are colinear because \\({\\overrightarrow{AC}}=2{\\overrightarrow{AB}}\\), or alternatively \\({\\overrightarrow{CA}}=2{\\overrightarrow{CB}}\\).",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#examples-for-displacements",
    "href": "week1.html#examples-for-displacements",
    "title": "Week 1: Displacement Vectors",
    "section": "Examples for displacements",
    "text": "Examples for displacements\n\nExample: Colinear points\nLet \\(A,B,C\\) be colinear, and \\({\\overrightarrow{AB}} = \\alpha {\\overrightarrow{AC}}\\), for \\(0 &lt; \\alpha &lt; 1\\).\nAlso, let \\(|{\\overrightarrow{AB}}| = \\lambda\\) and \\(|{\\overrightarrow{BC}}| = \\mu\\).\nFind \\(\\alpha\\) in terms of \\(\\lambda\\) and \\(\\mu\\).\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFrom Figure 4 we see that \\(|{\\overrightarrow{AC}}| = \\lambda+ \\mu\\). What is \\(\\alpha\\)?\nNow \\(| {\\overrightarrow{AB}} | = \\alpha |{\\overrightarrow{AC}}|\\), so that Thus \\({\\overrightarrow{AB}}= \\left(\\frac{\\lambda}{\\lambda+ \\mu}\\right) {\\overrightarrow{AC}}\\). Similary \\({\\overrightarrow{BC}}= \\left(\\frac{\\mu}{\\lambda+ \\mu}\\right) {\\overrightarrow{AC}}\\).\n\n\n\n\n\nExample: Parallelogram\nLet \\(RSTU\\) be a parallelogram (see Figure 5), and extend \\(RU\\) to \\(A\\) so that \\({\\overrightarrow{RU}} = {\\overrightarrow{UA}}\\). Also let \\(C\\) be the mid-point of \\(UT\\). Prove that \\(C\\) is the midpoint of \\(SA\\).\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe have \\[{\\overrightarrow{SA}} = {\\overrightarrow{SR}} + {\\overrightarrow{RA}} = {\\overrightarrow{TU}} + {\\overrightarrow{RA}} = 2\\,{\\overrightarrow{CU}} + 2\\, {\\overrightarrow{UA}} = 2 ({\\overrightarrow{CU}}+{\\overrightarrow{UA}})= 2\\, {\\overrightarrow{CA}}.\n\\] Thus \\(S,C,A\\) are colinear, and \\(C\\) is the mid-point of \\(SA\\).",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week1.html#footnotes",
    "href": "week1.html#footnotes",
    "title": "Week 1: Displacement Vectors",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn common language, we use “speed” and “velocity” interchangeably. In physics, velocity is a vector quantity and speed is a scalar, the magnitude of the velocity.↩︎",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 1: Displacement Vectors"
    ]
  },
  {
    "objectID": "week2.html#unit-vectors",
    "href": "week2.html#unit-vectors",
    "title": "Week 2: General Vectors",
    "section": "Unit vectors",
    "text": "Unit vectors\nA unit vector is a vector with magnitude equal to 1. We sometimes use a little hat to denote unit vectors, like \\(\\hat{{\\mathbf{a}}}\\). So \\(|\\hat{{\\mathbf{a}}}| = 1\\).\nSuppose you want to find a unit vector in the direction of another vector \\({\\mathbf{a}}\\). Well \\({\\mathbf{b}} = \\lambda {\\mathbf{a}}\\) is a vector in the right direction. Using the rules above, it has magnitude \\(|{\\mathbf{b}}|=|\\lambda{\\mathbf{a}}| = |\\lambda| |{\\mathbf{a}}|\\). So if we choose \\(\\lambda = \\frac{1}{|{\\mathbf{a}}|}\\), we have \\(|{\\mathbf{b}}| = \\frac{1}{|{\\mathbf{a}}|} |{\\mathbf{a}}| = 1\\). So \\({\\mathbf{b}}\\) is a unit vector in the direction of \\({\\mathbf{a}}\\).\n\n\n\n\n\n\nNote\n\n\n\nTo turn any vector into a unit vector, multiply it by one divided by the magnitude.",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week2.html#position-vectors",
    "href": "week2.html#position-vectors",
    "title": "Week 2: General Vectors",
    "section": "Position vectors",
    "text": "Position vectors\nSo far we’ve discussed points in space. If we choose a special point, called the origin \\(O\\), then we can define the position of any other point relative to this.\nSo given points \\(A\\) and \\(B\\), instead of just thinking about the displacement between them, if we choose an origin we can use vectos \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) to denote their positions relative to the origin.\n\n\n\n\n\n\n\nNote\n\n\n\nThe position vector of a point is just its displacement from the origin, \\({\\mathbf{a}}={\\overrightarrow{OA}}\\).\n\n\nThink: what is the displacement vector \\({\\overrightarrow{AB}}\\) in terms of the position vectors \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe know that \\({\\mathbf{a}}={\\overrightarrow{OA}}\\) and \\({\\mathbf{b}} = {\\overrightarrow{OB}}\\). Remember from our rules for displacements that \\({\\overrightarrow{AB}} = {\\overrightarrow{AO}}+{\\overrightarrow{OB}} = -{\\overrightarrow{OA}} + {\\overrightarrow{OB}}\\). So \\({\\overrightarrow{OA}} = -{\\mathbf{a}} + {\\mathbf{b}} = {\\mathbf{b}} - {\\mathbf{a}}\\).\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo get the displacement vector in terms of position vectors, subtract the position vector of the start from the position vector of the end.\n\n\n\n\n\n\n\n\nCommon mistake\n\n\n\nFor some reason people like to say that \\({\\overrightarrow{AB}}={\\mathbf{a}}+{\\mathbf{b}}\\). This is clearly wrong. Remember that \\({\\overrightarrow{BA}}=-{\\overrightarrow{AB}}\\).\n\n\nLater in the module, we’ll want to talk about a position vector for a general point in space. For historical reasons, this is usually written as \\({\\mathbf{r}}\\). Think of \\({\\mathbf{r}}\\) as an arrow pointing from the origin \\(O\\) to wherever you currently are.",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week2.html#basis-vectors",
    "href": "week2.html#basis-vectors",
    "title": "Week 2: General Vectors",
    "section": "Basis vectors",
    "text": "Basis vectors\nIn two dimensions, you can write any vector as a linear combination of any two other vectors that aren’t parallel.2\nThat means, if we have \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\) and these aren’t parallel, so there is no \\(\\lambda\\) such that \\({\\mathbf{a}}=\\lambda{\\mathbf{b}}\\), then for any vector \\({\\mathbf{c}}\\), we can find \\(\\alpha\\) and \\(\\beta\\) such that \\({\\mathbf{c}}=\\alpha{\\mathbf{a}}+\\beta{\\mathbf{b}}\\).\n\n\n\n\n\n\nNote\n\n\n\nWhen doing vector problems, choose two non-parallel vectors and write all the other vectors in terms of these.\n\n\nIt’s extra helpful if we choose two vectors that are orthogonal (at right angles) and unit vectors. Normally we choose a vector of length 1 in the horizontal direction and call this \\(\\hat{{\\mathbf{x}}}\\) and a vector of length 1 in the vertical direction and call this \\(\\hat{{\\mathbf{y}}}\\).\nThen for any vector \\({\\mathbf{a}}\\), we can find unique scalar numbers \\(a_1\\) and \\(a_2\\) such that \\({\\mathbf{a}} = a_1 \\hat{{\\mathbf{x}}} + a_2 \\hat{{\\mathbf{y}}}\\).\nIn fact, we do this so often that we introduce a new notation: \\[{\\mathbf{a}} = \\begin{bmatrix} a_1 \\\\ a_2 \\end{bmatrix}.\\] 3\nAnd the unit basis vectors are simply \\[\\hat{{\\mathbf{x}}} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\] and \\[\\hat{{\\mathbf{y}}} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\\]\nIn three dimensions we write \\[{\\mathbf{b}} = b_1 \\hat{{\\mathbf{x}}} + b_2 \\hat{{\\mathbf{y}}} + b_3 \\hat{{\\mathbf{z}}} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3\\end{bmatrix}.\\]\n\n\n\n\n\n\nNote\n\n\n\nVectors are not the same as coordinates! They are related but conceptually different. The position vector for the coordinates \\((3,4,5)\\) is \\(\\begin{bmatrix} 3 \\\\ 4 \\\\ 5\\end{bmatrix}\\), and we use the two different notations to distinguish them.\n\n\nFor the general position vector, the position in 3D space is given by the coordinates \\((x,y,z)\\) so \\({\\mathbf{r}} = \\begin{bmatrix} x \\\\ y \\\\ z\\end{bmatrix}\\).",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week2.html#column-vectors",
    "href": "week2.html#column-vectors",
    "title": "Week 2: General Vectors",
    "section": "Column vectors",
    "text": "Column vectors\nWith this new notation, everything behaves exactly as you would expect:\n\\[\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ -3 \\end{bmatrix} = \\begin{bmatrix} 5+1 \\\\ 2-3 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ -1 \\end{bmatrix}.\\]\n\\[4\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 4\\times 5 \\\\ 4\\times 2 \\end{bmatrix} = \\begin{bmatrix} 20 \\\\ 8 \\end{bmatrix}.\\]\nIf you’re unsure about any of these rules, you can rewrite \\(\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}\\) as \\(5\\hat{{\\mathbf{x}}}+2\\hat{{\\mathbf{y}}}\\) etc. and apply the list of rules above.\nOften we use the mathematical notation that \\[\\begin{bmatrix} -1 \\\\ 3 \\\\ -3\\end{bmatrix}\\in\\mathbb{R}^3.\\] This says that the vector lives in the set of obejcts which can be written as three real numbers. Obviously for 2D we write \\(\\mathbb{R}^2\\) instead.",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week2.html#pythagorass-rule",
    "href": "week2.html#pythagorass-rule",
    "title": "Week 2: General Vectors",
    "section": "Pythagoras’s rule",
    "text": "Pythagoras’s rule\nWe haven’t yet defined the magnitude of a general vector. What is the magnitude of \\(\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}\\)?\nFrom the rules so far, we know that \\[ \\left|\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}\\right| = \\left|5\\hat{{\\mathbf{x}}}+2\\hat{{\\mathbf{y}}}\\right| \\leq |5\\hat{{\\mathbf{x}}}| + |2\\hat{{\\mathbf{y}}}| = 5|\\hat{{\\mathbf{x}}}| + 2|\\hat{{\\mathbf{y}}}| = 5\\times1 + 2\\times1 = 7\\] but that just tells us that \\(\\left|\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}\\right|\\leq 7\\). This isn’t enough.\nActually there are lots of possible choices. In this module, we focus on normal, ‘flat’, Euclidean space: \\[\\left|\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}\\right| = \\sqrt{5^2 + 2^2} = \\sqrt{29}\\] which is less than 7, as expected.\nThen general rule is: \\[|{\\mathbf{a}}| = \\sqrt{a_1^2 + a_2^2}\\] and in 3D \\[|{\\mathbf{b}}| = \\sqrt{b_1^2 + b_2^2 + b_3^2}\\].\nTo convince yourself these are good definition, draw a diagram and use Pythagoras’s theorem.\n\n\n\n\n\n\nNote\n\n\n\nThe magnitude of a vector is the square root of the components squared and added up.\n\n\nThink: what is the magnitude of the vector \\(\\begin{bmatrix} 2 \\\\ -6 \\\\ -3\\end{bmatrix}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\sqrt{2^2 + (-6)^2 + (-3)^2} = \\sqrt{4 + 36 + 9} = \\sqrt{49} = 7.\\]\nDon’t let the negatives confuse you!",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week2.html#examples-for-general-vectors",
    "href": "week2.html#examples-for-general-vectors",
    "title": "Week 2: General Vectors",
    "section": "Examples for general vectors",
    "text": "Examples for general vectors\n\nExample 1\nLet \\(ABCDEF\\) be a regular hexagon with sides of length 1. Let \\(\\hat{{\\mathbf{v}}}\\) and \\(\\hat{{\\mathbf{w}}}\\) correspond to 2 adjacent sides, \\({\\overrightarrow{AB}} = \\hat{{\\mathbf{v}}}\\), \\({\\overrightarrow{AF}} = \\hat{{\\mathbf{w}}}\\) (where \\(A\\) is the bottom left point, and \\(A,B,C....\\) proceed anti-clockwise.)\nExpress all other sides and the diagonals in terms of \\(\\hat{{\\mathbf{v}}}\\) and \\(\\hat{{\\mathbf{w}}}\\). Also, find a unit vector in the direction \\(\\hat{{\\mathbf{w}}}-\\hat{{\\mathbf{v}}}\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSides: \\({\\overrightarrow{AB}}={\\overrightarrow{ED}}=\\hat{{\\mathbf{v}}}\\), \\(\\qquad{\\overrightarrow{AF}}= {\\overrightarrow{CD}}=\\hat{{\\mathbf{w}}}\\), \\(\\qquad{\\overrightarrow{BC}}= {\\overrightarrow{FE}}=\\hat{{\\mathbf{v}}} + \\hat{{\\mathbf{w}}}\\).\nDiagonals: \\({\\overrightarrow{FC}}=2\\hat{{\\mathbf{v}}}\\), \\(\\qquad{\\overrightarrow{BE}}=2\\hat{{\\mathbf{w}}}\\), \\(\\qquad{\\overrightarrow{AD}}=2(\\hat{{\\mathbf{v}}} + \\hat{{\\mathbf{w}}})\\).\nWe have \\(\\hat{{\\mathbf{w}}} - \\hat{{\\mathbf{v}}} = {\\overrightarrow{BF}} = {\\overrightarrow{CE}}\\).\nThe length of \\(\\hat{{\\mathbf{w}}} - \\hat{{\\mathbf{v}}}\\) is \\(\\sqrt{3}\\), which can be obtained from triangle \\(AFB\\). Thus a unit vector in direction of \\(\\hat{{\\mathbf{w}}} - \\hat{{\\mathbf{v}}}\\) is \\[\\frac{1}{\\sqrt{3}} ( \\hat{{\\mathbf{w}}} - \\hat{{\\mathbf{v}}}).\\]\n\n\n\n\n\nExample 2\nLet the points \\(A\\) and \\(B\\) have position vectors \\({\\mathbf{a}}\\) and \\({\\mathbf{b}}\\). Find the position vector of the midpoint of \\(A\\) and \\(B\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe midpoint of \\(A\\) and \\(B\\) is halfway along the line \\(AB\\). Call this point \\(C\\), and it must satisfy \\({\\overrightarrow{AC}}=\\frac{1}{2}{\\overrightarrow{AB}}\\).\nTo get to C from the origin, we can go via \\(A\\). So the position vector is \\[{\\overrightarrow{OC}} ={\\overrightarrow{OA}} + {\\overrightarrow{AC}} = {\\mathbf{a}} + \\frac{1}{2}{\\overrightarrow{AB}}.\\]\nRecall that \\({\\overrightarrow{AB}} = {\\mathbf{b}}-{\\mathbf{a}}\\) (remember this rule!), so finally \\[{\\overrightarrow{OC}} = {\\mathbf{a}} + \\frac{1}{2}\\left({\\mathbf{b}}-{\\mathbf{a}}\\right) = \\frac{1}{2}{\\mathbf{a}} + \\frac{1}{2}{\\mathbf{b}}.\\]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe position vector of the midpoint of two points is the average of the position vectors of the two points.",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week2.html#footnotes",
    "href": "week2.html#footnotes",
    "title": "Week 2: General Vectors",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhen writing vectors with pen and paper or on the board, bold is difficult, but there are various other possibilities and different people like different things. I use an underline. Whatever you choose, it’s very helpful to distinguish between vectors and scalars in your handwriting.↩︎\nIn three dimensions, we need to choose three vectors and so on.↩︎\nDifferent people write these vectors vertically or horizontally, with round or square brackets. It doesn’t really matter but it’s good to be consistent.↩︎",
    "crumbs": [
      "Chapter 1: Vectors",
      "Week 2: General Vectors"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "Week 4: Introduction to matrices",
    "section": "",
    "text": "We previously saw that we can think of vectors as column vectors, that is, a series of numbers in a column: \\[\n\\begin{bmatrix} 1 \\\\ 2 \\\\ 5\\end{bmatrix}\\in\\mathbb{R}^3,\n\\] and with this idea we defined addition and scalar multiplication in the obvious ways. We can extend this idea to larger grids of numbers, for example \\[\n\\begin{bmatrix} 1 &0 &-1\\\\3 & 2 & -2 \\end{bmatrix} \\in \\mathbb{R}^{2\\times3}.\n\\] This is called a matrix, in particular a \\(2\\times 3\\) real1 matrix2. There are two rows and three columns.\nWe typically write matrices with the following notation3: \\[\nA = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix},\n\\] \\[\nB = \\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\\\ b_{31} & b_{32} \\end{bmatrix},\n\\] etc.\nCapital, non-bold letters for the matrix, and lowercase letters with row then column for the scalar entries of the matrix. The only exception to this is that when there is only one column, we usually revert to our old notation of \\({\\mathbf{c}} = \\begin{bmatrix} c_1\\\\c_2\\\\c_3\\\\c_4 \\end{bmatrix}\\), because column vectors are matrices (sometimes called column matrices).\nThink: what shape are the matrices \\(A\\), \\(B\\) and \\({\\mathbf{c}}\\) above?\nSometimes we call the shape of a matrix its order.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 4: Introduction to matrices"
    ]
  },
  {
    "objectID": "week4.html#the-transpose",
    "href": "week4.html#the-transpose",
    "title": "Week 4: Introduction to matrices",
    "section": "The transpose",
    "text": "The transpose\nAn extra operation we use for matrices, which we use a lot, is called the transpose, denoted with a little letter T. This takes a matrix and exchanges the rows with the columns. So the transpose of a \\(5\\times 2\\) matrix is a \\(2\\times 5\\) matrix.\nIf \\[\nA=\\begin{bmatrix} 1 &3&4\\\\2&1&1 \\end{bmatrix}\n\\] its transpose is \\[\nA^T=\\begin{bmatrix} 1 &2\\\\3 & 1\\\\4&1 \\end{bmatrix}.\n\\]\nThink: what’s the transpose of \\(M=\\begin{bmatrix} 1& 2\\\\3& 4 \\end{bmatrix}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(M^T=\\begin{bmatrix} 1 &3\\\\2&4 \\end{bmatrix}\\)\n\n\n\n\n\n\n\n\n\nCommon mistake\n\n\n\nOften people flip over the wrong diagonal. The diagonal that starts at the top left is THE diagonal of a matrix, and it doesn’t change when we transpose.\n\n\n\nProperties of the transpose\nYou can easily prove the following statements:\n\nThe transpose of a square matrix is square.\nThe transpose of the transpose is the original matrix: \\(\\left(A^T\\right)^T=A\\).\nThe transpose of a product obeys \\((AB)^T = B^TA^T\\).\nThe transpose of a sum obeys \\((A+B)^T = A^T + B^T\\).",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 4: Introduction to matrices"
    ]
  },
  {
    "objectID": "week4.html#properties-of-matrix-multiplication",
    "href": "week4.html#properties-of-matrix-multiplication",
    "title": "Week 4: Introduction to matrices",
    "section": "Properties of matrix multiplication",
    "text": "Properties of matrix multiplication\nIt’s straightforward, if boring, to prove the following:\n\n\\(A(B+C) = AB+AC\\): it’s distributive over addition\n\\((AB)C = A(BC)\\): it’s associative.\nIt’s not commutative. \\(AB\\) is not the same as \\(BA\\). One may be possible and the other not possible.\nFor any matrix \\(A\\), and the identity matrix \\(I\\) (of the correct size for the multiplication to work) \\(AI = A\\) and \\(IA = A\\).",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 4: Introduction to matrices"
    ]
  },
  {
    "objectID": "week4.html#properties-of-the-inverse",
    "href": "week4.html#properties-of-the-inverse",
    "title": "Week 4: Introduction to matrices",
    "section": "Properties of the inverse",
    "text": "Properties of the inverse\nUsing arguments similar to that above, you could prove the following for \\(2\\times2\\) inverses:4\n\nThe inverse of a square matrix is square.\nIf the inverse exists, it is both a right- and left- inverse, even though matrix multiplication is not commutation. So \\(AA^{-1}=I\\) means \\(A^{-1}A = I\\).\nThe inverse is unique. If \\(AB=I\\), then \\(B=A^{-1}\\) and \\(A=B^{-1}\\).\nThe inverse of the inverse is the original matrix: \\(\\left(A^{-1}\\right)^{-1}=A\\).\nThe inverse of the transpose is the transpose of the inverse: \\(\\left(A^T\\right)^{-1}=\\left(A^{-1}\\right)^T\\).\nThe inverse of a product obeys \\((AB)^{-1} = B^{-1}A^{-1}\\).",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 4: Introduction to matrices"
    ]
  },
  {
    "objectID": "week4.html#footnotes",
    "href": "week4.html#footnotes",
    "title": "Week 4: Introduction to matrices",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEventually you’ll see matrices with complex numbers inside.↩︎\nPronounced “two by three”.↩︎\nAgain, many authors use round brackets. You can too if you like.↩︎\nIn fact they hold for any sized square matrix.↩︎",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 4: Introduction to matrices"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "Week 6: Applications of matrices, and Gaussian elimination",
    "section": "",
    "text": "\\[\n\\newenvironment{amatrix}[1]{%\n  \\left[\\begin{array}{#1}\n}{%\n  \\end{array}\\right]\n}\n\\]",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 6: Applications of matrices, and Gaussian elimination"
    ]
  },
  {
    "objectID": "week6.html#rotation-matrices",
    "href": "week6.html#rotation-matrices",
    "title": "Week 6: Applications of matrices, and Gaussian elimination",
    "section": "Rotation matrices",
    "text": "Rotation matrices\nThe following matrix rotates vectors around the origin by an angle \\(\\theta\\) anticlockwise: \\[\nR_\\theta = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}\n\\] Why? Consider a position vector \\(\\mathbf{a}=\\begin{bmatrix} r\\cos\\alpha \\\\ r\\sin\\alpha \\end{bmatrix}\\). This is \\(\\begin{bmatrix} x \\\\ y \\end{bmatrix}\\) at polar coordinates \\((r,\\alpha)\\), which hopefully you’ve seen before.\nThen applying the matrix, \\[\n{\\mathbf{b}} = R_\\theta \\mathbf{r} = \\begin{bmatrix} r\\cos\\alpha\\cos\\theta - r \\sin\\alpha\\sin\\theta \\\\ r\\cos\\alpha\\sin\\theta + r\\sin\\alpha\\cos\\theta \\end{bmatrix} = \\begin{bmatrix} r\\cos{(\\alpha+\\theta)} \\\\ r\\sin(\\alpha+\\theta) \\end{bmatrix}\n\\] which is the position vector with polar coordinates \\((r,\\alpha+\\theta)\\). This diagram might help: \nThink: What’s the determinant of the rotation matrix \\(R_\\theta\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(\\cos\\theta\\cos\\theta - (-\\sin\\theta)\\sin\\theta = \\cos^2 \\theta + \\sin^2\\theta = 1\\).",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 6: Applications of matrices, and Gaussian elimination"
    ]
  },
  {
    "objectID": "week6.html#reflection-matrices",
    "href": "week6.html#reflection-matrices",
    "title": "Week 6: Applications of matrices, and Gaussian elimination",
    "section": "Reflection matrices",
    "text": "Reflection matrices\nConsider the matrix \\[\nP=\\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}.\n\\] Then \\(P{\\mathbf{x}} = [x_1,-x_2]\\). All it’s done is reversed the \\(y\\) component. In other words, we’ve reflected over the \\(x\\)-axis.\nSimilarly, \\[\nQ=\\begin{bmatrix} -1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n\\] applied to any vector is just a reflection over the \\(y\\)-axis.\nThink: What’s the determinant of the reflection matrix \\(P\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(1\\times-1 - 0 = -1\\)\n\n\n\nAll reflections have determinant \\(-1\\), and all rotations have determinant \\(+1\\). You can think of the determinant as a scale factor for areas: rotations don’t change the area, and reflections flip it.\nTo get a reflection through a different line, you can always use a combination of rotations and reflections.\nThe matrix given by \\[\nR_{\\theta} P R_{-\\theta}\n\\] reflects in the line which makes angle \\(\\theta\\) with the \\(x\\)-axis: first we rotate by \\(-\\theta\\), then reflect over the \\(x\\)-axis, then rotate back.\nMany more transformations exist, such as shear and projection. In 3D they get much more complicated. This sort of matrix is used extensively in the development of video games and computer graphics.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 6: Applications of matrices, and Gaussian elimination"
    ]
  },
  {
    "objectID": "week6.html#gaussian-elimination",
    "href": "week6.html#gaussian-elimination",
    "title": "Week 6: Applications of matrices, and Gaussian elimination",
    "section": "Gaussian elimination",
    "text": "Gaussian elimination\nWe’ve actually already seen Gaussian elimination, for calculating the inverse of \\(3\\times3\\) matrices. The principle here is the same: perform a series of row operations to simplify the matrix:\n\nStart with a linear system of equations.\nWrite this as a matrix equation \\(A{\\mathbf{x}}={\\mathbf{b}}\\) where \\(A\\) and \\({\\mathbf{b}}\\) are known, and we want to find \\({\\mathbf{x}}\\).\nWrite an augmented matrix \\([A|{\\mathbf{b}}]\\).\nPerform a series of row operations to reduce \\(A\\) to row-echelon form.\nTransform back to a series of equations.\nUse this form to read off the solution.\n\nThese steps should become clear when we see an example. First we need to know what row-echelon form means.\n\nRow-echelon form\nA matrix is in row-echelon form if each row has more zeros at the start than the preceding row (unless they’re all zero). It is always possible to convert a matrix into this form.\nThink: which of the following matrices are in row-echelon form?\n\\[\nA = \\begin{bmatrix} 1 & 2 & 3\\\\0 & 5 & 6\\\\0&0&1 \\end{bmatrix}, B=\\begin{bmatrix} 1 & 0 &0\\\\0 & 0 &0 \\\\ 0 & 0 &0 \\end{bmatrix}, C=\\begin{bmatrix} 1 & 0 & 0\\\\0 & 0 &-4\\\\ 0 & 0 &1 \\end{bmatrix}\n\\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(A\\) is very standard row-echelon form. \\(B\\) is in row echelon form, but \\(C\\) is not because the final row doesn’t have more leading zeros than the previous one.\n\n\n\n\n\nExample 1\nLet’s solve the following system via Gaussian elimination:1\n\\[\n\\begin{aligned}\nx_1 + 2x_2 + 3x_3 &= 1,\\\\\n4x_1+5x_2+6x_3 &= 2,\\\\\n7x_1+8x_2+8x_3 &= 3.\n\\end{aligned}\n\\] First we rewrite this as a matrix equation: \\[\n\\begin{bmatrix} 1&2&3\\\\4&5&6\\\\7&8&8 \\end{bmatrix} {\\mathbf{x}} = \\begin{bmatrix} 1\\\\2\\\\3 \\end{bmatrix}\n\\] and then this can be represented with an augmented matrix as \\[\n\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n4&5&6&2\\\\\n7&8&8&3\n\\end{amatrix}.\n\\] Now let’s put it in row echelon form using row operations, just like last week. We need a zero at the start of the second row: \\[\n\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n0&-3&-6&-2\\\\\n7&8&8&3\n\\end{amatrix} \\qquad R_2 \\to R_2 - 4 R_1,\n\\] a zero at the start of the third row: \\[\n\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n0&-3&-6&-2\\\\\n0&-6&-13&-4\n\\end{amatrix} \\qquad R_3 \\to R_3 - 7 R_1,\n\\] and another zero at the start of the third row \\[\n\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n0&-3&-6&-2\\\\\n0&0&-1&0\n\\end{amatrix} \\qquad R_3 \\to R_3 - 2 R_2,\n\\] This is now in row echelon form. How does this help us? Well, if we write this back as a system of equations we now have \\[\n\\begin{aligned}\nx_1 + 2x_2 + 3x_3 &= 1,\\\\\n-3x_2-6x_3 &= -2,\\\\\n-x_3&=0.\n\\end{aligned}\n\\] So immediately we know that we must have \\(x_3=0\\). Then the second of these equations gives us \\(-3x_2=-2\\), so \\(x_2=\\frac{2}{3}\\), and finally plugging this into the first equation we find \\(x_1=-\\frac{1}{3}\\).\nBasically, this method formalises techniques you may have seen before for solving simultaneous equations. It’s particularly useful because it allows us to deal with singular matrices too:\n\n\nZero rows\nWhat if we perform Gaussian elimination and get to a point where the final row is all zeros? This happens exactly when the initial matrix is singular, and it means we can’t follow the above procedure to find a unique solution to the system. Instead, we either have no solutions or an infinite number of solutions, depending on whether the final row gives us \\(0=0\\) or \\(0=1\\). The second case is impossible, so we have no solutions, whereas if we get \\(0=0\\) then we have only 2 equations for 3 unknowns, so there are infinitely many solutions.\n\n\nExample 2\nSimilar to the previous example, let’s consider: \\[\n\\begin{aligned}\nx_1 + 2x_2 + 3x_3 &= 1,\\\\\n4x_1+5x_2+6x_3 &= 2,\\\\\n7x_1+8x_2+9x_3 &= 3.\n\\end{aligned}\n\\] Proceeding as before, we have \\[\n\\begin{aligned}\n&\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n4&5&6&2\\\\\n7&8&9&3\n\\end{amatrix}\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n0&-3&-6&-2\\\\\n7&8&9&3\n\\end{amatrix} \\qquad R_2 \\to R_2 - 4 R_1,\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n0&-3&-6&-2\\\\\n0&-6&-12&-4\n\\end{amatrix} \\qquad R_3 \\to R_3 - 7 R_1,\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&2&3&1\\\\\n0&-3&-6&-2\\\\\n0&0&0&0\n\\end{amatrix} \\qquad R_3 \\to R_3 - 2 R_2,\\\\\n\\end{aligned}\n\\] This is in row echelon form. Now the system of equations is \\[\n\\begin{aligned}\nx_1 + 2x_2 + 3x_3 &= 1,\\\\\n-3x_2-6x_3 &= -2,\\\\\n0&=0.\n\\end{aligned}\n\\] The final row doesn’t tell us anything, so there are infinitely many solutions. To proceed, and follow the usual process of working backwards to first find \\(x_3\\), then \\(x_2\\) and then \\(x_1\\), let’s say that \\(x_3=\\alpha\\), some number that we don’t know.\nThen the second equation says \\(x_2 = \\frac{2}{3} - 2x_3 = \\frac{2}{3}-2\\alpha\\), and the first equation gives \\(x_1 = 1-2x_2-3x_3=-\\frac{1}{3}+\\alpha\\). This is a solution for any value of \\(\\alpha\\), and thus there are infinitely many solutions.",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 6: Applications of matrices, and Gaussian elimination"
    ]
  },
  {
    "objectID": "week6.html#footnotes",
    "href": "week6.html#footnotes",
    "title": "Week 6: Applications of matrices, and Gaussian elimination",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe two 8s in the final equation are deliberate, otherwise it would have been singular.↩︎",
    "crumbs": [
      "Chapter 2: Matrices",
      "Week 6: Applications of matrices, and Gaussian elimination"
    ]
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "Week 8: Planes",
    "section": "",
    "text": "\\[\n\\newenvironment{amatrix}[1]{%\n  \\left[\\begin{array}{#1}\n}{%\n  \\end{array}\\right]\n}\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#normals",
    "href": "week8.html#normals",
    "title": "Week 8: Planes",
    "section": "Normals",
    "text": "Normals\nA normal, which is always given the letter \\({\\mathbf{n}}\\), is a vector which is pointing in a direction that is perpendicular to all the directions on the plane. In particular, if we have a plane in the form above, then the normal must be perpendicular to the vectors \\({\\mathbf{s}}\\) and \\({\\mathbf{t}}\\). So we can find a normal by using the cross product! \\[\n{\\mathbf{n}} = {\\mathbf{s}}\\times{\\mathbf{t}}.\n\\] Note that the normal is not unique, it can be any scalar multiple of this1. Sometimes we want a unit normal vector, called \\(\\hat{{\\mathbf{n}}}\\), but that’s easy to find: just divide by the length. Even the unit normal isn’t unique, because it could point up or down.\nThink: what is a normal for the plane containing the points with position vectors \\({\\mathbf{a}}\\), \\({\\mathbf{b}}\\) and \\({\\mathbf{c}}\\)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe need to find two vectors that lie flat on the plane. The position vectors themselves don’t satisfy this, but the displacements \\({\\overrightarrow{AB}}\\) and \\({\\overrightarrow{AC}}\\) (or any other combination) do: \\[\n{\\mathbf{n}} = {\\overrightarrow{AB}}\\times{\\overrightarrow{AC}} = ({\\mathbf{b}}-{\\mathbf{a}})\\times({\\mathbf{c}}-{\\mathbf{a}}).\n\\]\nIf we knew values for \\({\\mathbf{a}}\\), \\({\\mathbf{b}}\\) and \\({\\mathbf{c}}\\) we could calculate this quantity.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#a-general-equation-for-a-plane",
    "href": "week8.html#a-general-equation-for-a-plane",
    "title": "Week 8: Planes",
    "section": "A general equation for a plane",
    "text": "A general equation for a plane\nFor a flat plane, any displacement vector that lies on the plane must be perpendicular to the normal. We can write an equation for a plane just knowing the normal \\({\\mathbf{n}}\\) and one point on the plane \\({\\mathbf{a}}\\) as follows:\nFor any general point on the plane with position vector \\({\\mathbf{r}}\\), the displacement vector from our point \\({\\mathbf{a}}\\) to this point is \\({\\mathbf{r}}-{\\mathbf{a}}\\). This vector is perpendicular to \\({\\mathbf{n}}\\), i.e. \\[\n({\\mathbf{r}}-{\\mathbf{a}})\\cdot{\\mathbf{n}} = 0,\n\\] which we arrange to the general form \\[\n{\\mathbf{r}}\\cdot{\\mathbf{n}} = {\\mathbf{a}}\\cdot{\\mathbf{n}}.\n\\] \nWe’ll see in some examples later that this form is much more useful than the one above, and if you’re asked for the equation of a plane, you should use this as the general formula.\nNotice that if we know what \\({\\mathbf{a}}\\) and \\({\\mathbf{n}}\\) are, the right-hand side here is just a number. And the left-hand side can easily be expanded using \\({\\mathbf{r}} = [x,y,z]\\). So a typical plane equation looks like this: \\[\n5x+2y-z= 3.\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#example",
    "href": "week8.html#example",
    "title": "Week 8: Planes",
    "section": "Example",
    "text": "Example\nFind an equation for the plane containing the points \\((1,2,3)\\), \\((4,5,6)\\) and \\((3,2,1)\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can find a normal vector using a cross product of two displacements on the plane: \\[\n{\\mathbf{n}} = ([4,5,6]-[1,2,3])\\times([3,2,1]-[1,2,3]) = [3,3,3]\\times[2,0,-2] = [-6, 12, -6]\n\\]\nThen we can take \\({\\mathbf{a}}=[1,2,3]\\) as our known point on the plane, and the standard formula \\({\\mathbf{r}}\\cdot{\\mathbf{n}} = {\\mathbf{a}}\\cdot{\\mathbf{n}}\\) gives \\[\n{\\mathbf{r}}\\cdot[-6,12,-6] = [1,2,3]\\cdot[-6,12,-6] = 0\n\\] or in other words \\[\n-6x + 12 y - 6z = 0,\n\\] which can be simplified to \\[\n-x+2y-z = 0.\n\\]\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnce you’ve found your plane equation, check that the three original points satisfy it – if they do this means you haven’t made a mistake.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#the-intersection-of-a-line-and-a-plane",
    "href": "week8.html#the-intersection-of-a-line-and-a-plane",
    "title": "Week 8: Planes",
    "section": "The intersection of a line and a plane",
    "text": "The intersection of a line and a plane\nAny time you see intersections mentioned, you should immediately think about solving equations. If a point is on the intersection of two objects, it must satisfy the equations for both objects. In the case of a line and a plane we know that \\[\n{\\mathbf{r}} = {\\mathbf{a}}+\\lambda{\\mathbf{s}}\\] and also \\[\n{\\mathbf{r}}\\cdot{\\mathbf{n}} = d\\] for some known vectors \\({\\mathbf{a}}\\), \\({\\mathbf{s}}\\) and \\({\\mathbf{n}}\\) and a scalar \\(d\\). The only unknown is \\(\\lambda\\), which will tell us where the intersection is.\nSince both of these are satisfied, we can just substitute \\({\\mathbf{r}}\\) from the first equation int the second to give \\[\n({\\mathbf{a}}+\\lambda{\\mathbf{s}})\\cdot {\\mathbf{n}} = d,\n\\] which is then rearranged to give a value for \\(\\lambda\\) and then finally to find the point of intersection.\nThink: When could this procedure go wrong?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf \\({\\mathbf{s}}\\cdot{\\mathbf{n}}=0\\) then the above equation won’t give us \\(\\lambda\\) - we’d end up trying to divide by zero. This is equactly the case when the line is parallel to the plane. We’d either have no intersections, or the line would be on the plane, giving infinitely many intersections.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#the-intersection-of-two-planes",
    "href": "week8.html#the-intersection-of-two-planes",
    "title": "Week 8: Planes",
    "section": "The intersection of two planes",
    "text": "The intersection of two planes\nThis case is a bit different. Two flat planes can’t intersect at exactly one point. Either they don’t intersect at all – if the planes are parallel – or they intersect along a line. How can we find this line?\nGaussian elimination!\n\nExample\nFind the line of intersection of the two planes given by \\(x+y=0\\) and \\(x+y+z=12\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nActually this one’s easy if we spot that we can substitute the first equation into the second to find that \\(z=12\\), and then \\(y=-x\\) gives the line for this \\(z\\) value. But here’s how we would approach it in general: \\[\n\\begin{aligned}\n&\\begin{amatrix}{ccc|c}\n1&1&0&0\\\\1&1&1&12\n\\end{amatrix}\n\\\\\n&\\hookrightarrow\\begin{amatrix}{ccc|c}\n1&1&0&0\\\\0&0&1&12\n\\end{amatrix} \\qquad R_2 \\to R_2-R_1 \\qquad \\text{(to get a 0 on the bottom left)}\n\\end{aligned}\n\\] This is now in row-echelon form, so transforming back to equations, \\(x+y=0\\) and \\(z=12\\). Clearly there are infinitely many solutions. Let \\(y=\\lambda\\), then \\(x=-\\lambda\\), so the final line equation is \\[\n\\mathbf{r} = [0,0,12] + \\lambda[-1,1,0].\n\\]",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#the-distance-between-a-point-and-a-plane",
    "href": "week8.html#the-distance-between-a-point-and-a-plane",
    "title": "Week 8: Planes",
    "section": "The distance between a point and a plane",
    "text": "The distance between a point and a plane\nSuppose we have a point \\(B\\) with position vector \\({\\mathbf{b}}\\) and plane with equation \\[\n{\\mathbf{r}}\\cdot{\\mathbf{n}} = d.\n\\]\nJust like when we found the distance between a point and a line, the shortest distance is the displacement that’s perpendicular to the plane. Call the closest point on the plane \\(P\\), with position vector \\({\\mathbf{p}}\\). We want to find \\(|{\\overrightarrow{PB}}|\\).\nWe know that \\({\\mathbf{p}}\\cdot{\\mathbf{n}} = d\\), and we also know that \\({\\overrightarrow{PB}} = \\alpha{\\mathbf{n}}\\) for some \\(\\alpha\\), because the displacement must be perpendicular to the plane.\nHow can we put these two things together in an equation? \\[\n\\alpha{\\mathbf{n}}\\cdot{\\mathbf{n}} = {\\overrightarrow{PB}}\\cdot{\\mathbf{n}} = ({\\mathbf{b}}-{\\mathbf{p}})\\cdot{\\mathbf{n}} = {\\mathbf{b}}\\cdot{\\mathbf{n}} - {\\mathbf{p}}\\cdot{\\mathbf{n}} = {\\mathbf{b}}\\cdot{\\mathbf{n}} - d.\n\\] If we know \\({\\mathbf{b}}\\), \\({\\mathbf{n}}\\) and \\(d\\) then we now know \\[\n\\alpha = \\frac{{\\mathbf{b}}\\cdot{\\mathbf{n}} - d}{|{\\mathbf{n}}|^2}\n\\] and finally the shortest distance is \\[\n|{\\overrightarrow{PB}}| = \\frac{{\\mathbf{b}}\\cdot{\\mathbf{n}} - d}{|{\\mathbf{n}}|}.\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nYou could learn this formula/write it on your cheatsheet but I think it’s important to know how to derive it.",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#the-angle-between-a-line-and-a-plane",
    "href": "week8.html#the-angle-between-a-line-and-a-plane",
    "title": "Week 8: Planes",
    "section": "The angle between a line and a plane",
    "text": "The angle between a line and a plane\nIf a line intersects a plane, it will form some minimum angle \\(\\theta\\) with the plane. This is easy to calculate when you spot that \\(\\pi/2-\\theta\\) is the angle between the line and the normal to the plane. And you can find this with a dot product between \\({\\mathbf{s}}\\) and \\({\\mathbf{n}}\\).",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  },
  {
    "objectID": "week8.html#footnotes",
    "href": "week8.html#footnotes",
    "title": "Week 8: Planes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExcept zero times this of course↩︎",
    "crumbs": [
      "Chapter 3: Lines, planes and spheres",
      "Week 8: Planes"
    ]
  }
]